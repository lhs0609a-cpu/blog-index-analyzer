"""
ìë™ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ (Auto Learning Scheduler)
- ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§€ì†ì ìœ¼ë¡œ í‚¤ì›Œë“œ í•™ìŠµ
- ë„¤ì´ë²„ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ì†ë„ ì¡°ì ˆ
- í•™ìŠµ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ìë™ ëª¨ë¸ ì—…ë°ì´íŠ¸
"""
import asyncio
import threading
import time
import random
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional
import json

logger = logging.getLogger(__name__)

# ==============================================
# ì„¤ì •
# ==============================================
AUTO_LEARNING_CONFIG = {
    "enabled": True,                    # ìë™ í•™ìŠµ í™œì„±í™” ì—¬ë¶€
    "interval_minutes": 1,              # í•™ìŠµ ì£¼ê¸° (ë¶„)
    "keywords_per_cycle": 1,            # í•œ ë²ˆì— í•™ìŠµí•  í‚¤ì›Œë“œ ìˆ˜
    "blogs_per_keyword": 13,            # í‚¤ì›Œë“œë‹¹ ë¶„ì„í•  ë¸”ë¡œê·¸ ìˆ˜
    "delay_between_keywords": 5.0,      # í‚¤ì›Œë“œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    "delay_between_blogs": 1.0,         # ë¸”ë¡œê·¸ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    "auto_train_threshold": 50,         # ìë™ í›ˆë ¨ íŠ¸ë¦¬ê±° ìƒ˜í”Œ ìˆ˜
    "quiet_hours_start": 2,             # ì¡°ìš©í•œ ì‹œê°„ ì‹œì‘ (ì„œë²„ ë¶€í•˜ ê°ì†Œ)
    "quiet_hours_end": 6,               # ì¡°ìš©í•œ ì‹œê°„ ë
    "quiet_hours_interval": 60,         # ì¡°ìš©í•œ ì‹œê°„ëŒ€ í•™ìŠµ ì£¼ê¸° (ë¶„)
    "daily_training_hour": 3,           # ë§¤ì¼ ëŒ€ê·œëª¨ í›ˆë ¨ ì‹œê°„ (UTC, í•œêµ­ì‹œê°„ 12ì‹œ)
    "daily_training_samples": 5000,     # ëŒ€ê·œëª¨ í›ˆë ¨ ì‹œ ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜
}

# í•™ìŠµ ìƒíƒœ
auto_learning_state = {
    "is_running": False,
    "is_enabled": True,
    "last_run": None,
    "next_run": None,
    "total_keywords_learned": 0,
    "total_blogs_analyzed": 0,
    "total_cycles": 0,
    "errors": [],
    "current_keyword": None,
    "samples_since_last_train": 0,
    "last_daily_training": None,
    "daily_training_accuracy": None,
}

# í‚¤ì›Œë“œ í’€ (ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ë¡œí…Œì´ì…˜)
ROTATING_KEYWORDS = [
    # ì˜ë£Œ
    "ê°•ë‚¨ì¹˜ê³¼", "ì„í”Œë€íŠ¸", "êµì •ì¹˜ê³¼", "í”¼ë¶€ê³¼", "ì„±í˜•ì™¸ê³¼", "ë‚´ê³¼", "ì •í˜•ì™¸ê³¼",
    # ë§›ì§‘
    "ê°•ë‚¨ë§›ì§‘", "í™ëŒ€ë§›ì§‘", "ì´íƒœì›ë§›ì§‘", "ì‚¼ê²¹ì‚´ë§›ì§‘", "ì´ˆë°¥ë§›ì§‘", "íŒŒìŠ¤íƒ€ë§›ì§‘",
    # ì—¬í–‰
    "ì œì£¼ì—¬í–‰", "ë¶€ì‚°ì—¬í–‰", "ì˜¤ì‚¬ì¹´ì—¬í–‰", "ë„ì¿„ì—¬í–‰", "ë°©ì½•ì—¬í–‰", "ë°œë¦¬ì—¬í–‰",
    # ë·°í‹°
    "í™”ì¥í’ˆì¶”ì²œ", "ì„ í¬ë¦¼ì¶”ì²œ", "ìƒ´í‘¸ì¶”ì²œ", "ë‹¤ì´ì–´íŠ¸", "í™ˆíŠ¸ë ˆì´ë‹",
    # ìƒí™œ
    "ì´ì‚¬ì—…ì²´", "ì²­ì†Œì—…ì²´", "ì¸í…Œë¦¬ì–´", "ëƒ‰ì¥ê³ ì¶”ì²œ", "ì—ì–´ì»¨ì¶”ì²œ",
    # êµìœ¡
    "ì˜ì–´í•™ì›", "ìˆ˜í•™í•™ì›", "ì½”ë”©í•™ì›", "í† ìµ", "ê³µë¬´ì›ì‹œí—˜",
    # IT
    "ì•„ì´í°", "ê°¤ëŸ­ì‹œ", "ë§¥ë¶", "ë…¸íŠ¸ë¶ì¶”ì²œ", "ëª¨ë‹ˆí„°ì¶”ì²œ",
    # ì·¨ë¯¸
    "ê³¨í”„", "í…Œë‹ˆìŠ¤", "ë“±ì‚°", "ìº í•‘", "ë‚šì‹œ",
    # ë°˜ë ¤ë™ë¬¼
    "ê°•ì•„ì§€ë¶„ì–‘", "ê³ ì–‘ì´ë¶„ì–‘", "ê°•ì•„ì§€ì‚¬ë£Œ", "ë™ë¬¼ë³‘ì›",
    # ì›¨ë”©
    "ì›¨ë”©í™€", "ì›¨ë”©ë“œë ˆìŠ¤", "ì‹ í˜¼ì—¬í–‰", "ê²°í˜¼ë°˜ì§€",
    # ìœ¡ì•„
    "ì¶œì‚°ì¤€ë¹„", "ìœ ëª¨ì°¨", "ì¹´ì‹œíŠ¸", "ì•„ê¸°ìš©í’ˆ",
]

# ì´ë¯¸ í•™ìŠµí•œ í‚¤ì›Œë“œ ì¶”ì 
learned_keywords_today = set()
keyword_index = 0


def get_next_keywords(count: int) -> List[str]:
    """ë‹¤ìŒ í•™ìŠµí•  í‚¤ì›Œë“œ ì„ íƒ (ë¡œí…Œì´ì…˜)"""
    global keyword_index, learned_keywords_today

    keywords = []
    attempts = 0
    max_attempts = len(ROTATING_KEYWORDS) * 2

    while len(keywords) < count and attempts < max_attempts:
        keyword = ROTATING_KEYWORDS[keyword_index % len(ROTATING_KEYWORDS)]
        keyword_index += 1
        attempts += 1

        # ì˜¤ëŠ˜ ì´ë¯¸ í•™ìŠµí•œ í‚¤ì›Œë“œëŠ” ìŠ¤í‚µ
        if keyword not in learned_keywords_today:
            keywords.append(keyword)
            learned_keywords_today.add(keyword)

    # í•˜ë£¨ê°€ ì§€ë‚˜ë©´ ë¦¬ì…‹
    if datetime.now().hour == 0 and datetime.now().minute < 35:
        learned_keywords_today.clear()

    return keywords


def get_current_interval() -> int:
    """í˜„ì¬ ì‹œê°„ì— ë§ëŠ” í•™ìŠµ ê°„ê²© ë°˜í™˜ (ë¶„)"""
    hour = datetime.now().hour
    config = AUTO_LEARNING_CONFIG

    # ì¡°ìš©í•œ ì‹œê°„ëŒ€ì—ëŠ” ê°„ê²© ëŠ˜ë¦¼
    if config["quiet_hours_start"] <= hour < config["quiet_hours_end"]:
        return config["quiet_hours_interval"]

    return config["interval_minutes"]


async def run_single_learning_cycle():
    """ë‹¨ì¼ í•™ìŠµ ì‚¬ì´í´ ì‹¤í–‰"""
    global auto_learning_state

    if not auto_learning_state["is_enabled"]:
        return

    auto_learning_state["is_running"] = True
    auto_learning_state["last_run"] = datetime.now(timezone.utc).isoformat()

    try:
        # í•„ìš”í•œ ëª¨ë“ˆ ë™ì  ì„í¬íŠ¸
        from routers.blogs import fetch_naver_search_results, analyze_blog, analyze_post
        from database.learning_db import add_learning_sample, get_learning_samples, get_current_weights, save_current_weights
        from services.learning_engine import instant_adjust_weights

        config = AUTO_LEARNING_CONFIG
        keywords = get_next_keywords(config["keywords_per_cycle"])

        if not keywords:
            logger.info("No new keywords to learn this cycle")
            return

        logger.info(f"[AutoLearn] Starting cycle with keywords: {keywords}")

        for keyword in keywords:
            if not auto_learning_state["is_enabled"]:
                break

            auto_learning_state["current_keyword"] = keyword

            try:
                # ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                search_results = await fetch_naver_search_results(
                    keyword,
                    limit=config["blogs_per_keyword"]
                )

                if not search_results:
                    logger.warning(f"[AutoLearn] No results for: {keyword}")
                    continue

                blogs_analyzed = 0

                for result in search_results:
                    if not auto_learning_state["is_enabled"]:
                        break

                    try:
                        blog_id = result["blog_id"]
                        actual_rank = result["rank"]
                        post_url = result.get("post_url", "")

                        # ë¸”ë¡œê·¸ ë¶„ì„
                        analysis = await analyze_blog(blog_id)
                        stats = analysis.get("stats", {})
                        index = analysis.get("index", {})
                        breakdown = index.get("score_breakdown", {})
                        c_rank_detail = breakdown.get("c_rank_detail", {})
                        dia_detail = breakdown.get("dia_detail", {})

                        # ê¸€ ë¶„ì„ (ì„ íƒì )
                        post_features = {}
                        if post_url:
                            try:
                                post_analysis = await analyze_post(post_url, keyword)
                                post_features = {
                                    "title_has_keyword": post_analysis.get("title_has_keyword", False),
                                    "content_length": post_analysis.get("content_length", 0),
                                    "image_count": post_analysis.get("image_count", 0),
                                    "keyword_count": post_analysis.get("keyword_count", 0),
                                    "keyword_density": post_analysis.get("keyword_density", 0),
                                }
                            except Exception as e:
                                logger.debug(f"Post analysis skipped: {e}")

                        # í•™ìŠµ ìƒ˜í”Œ ì €ì¥
                        blog_features = {
                            "c_rank_score": breakdown.get("c_rank", 0),
                            "dia_score": breakdown.get("dia", 0),
                            "context_score": c_rank_detail.get("context", 50),
                            "content_score": c_rank_detail.get("content", 50),
                            "chain_score": c_rank_detail.get("chain", 50),
                            "depth_score": dia_detail.get("depth", 50),
                            "information_score": dia_detail.get("information", 50),
                            "accuracy_score": dia_detail.get("accuracy", 50),
                            "post_count": stats.get("total_posts", 0),
                            "neighbor_count": stats.get("neighbor_count", 0),
                            "visitor_count": stats.get("total_visitors", 0),
                            **post_features
                        }

                        add_learning_sample(
                            keyword=keyword,
                            blog_id=blog_id,
                            actual_rank=actual_rank,
                            predicted_score=index.get("total_score", 0),
                            blog_features=blog_features
                        )

                        blogs_analyzed += 1
                        auto_learning_state["total_blogs_analyzed"] += 1
                        auto_learning_state["samples_since_last_train"] += 1

                        # ë¸”ë¡œê·¸ ê°„ ë”œë ˆì´
                        await asyncio.sleep(config["delay_between_blogs"])

                    except Exception as e:
                        logger.warning(f"[AutoLearn] Blog analysis error: {e}")

                auto_learning_state["total_keywords_learned"] += 1
                logger.info(f"[AutoLearn] Completed {keyword}: {blogs_analyzed} blogs")

                # í‚¤ì›Œë“œ ê°„ ë”œë ˆì´
                await asyncio.sleep(config["delay_between_keywords"])

            except Exception as e:
                logger.error(f"[AutoLearn] Keyword error {keyword}: {e}")
                auto_learning_state["errors"].append({
                    "time": datetime.now(timezone.utc).isoformat(),
                    "keyword": keyword,
                    "error": str(e)
                })

        # ìë™ í›ˆë ¨ ì²´í¬
        if auto_learning_state["samples_since_last_train"] >= config["auto_train_threshold"]:
            await run_auto_training()

        auto_learning_state["total_cycles"] += 1
        auto_learning_state["current_keyword"] = None

        # ì—ëŸ¬ ë¡œê·¸ ìµœëŒ€ 20ê°œ ìœ ì§€
        if len(auto_learning_state["errors"]) > 20:
            auto_learning_state["errors"] = auto_learning_state["errors"][-20:]

    except Exception as e:
        logger.error(f"[AutoLearn] Cycle failed: {e}")
        import traceback
        traceback.print_exc()

    finally:
        auto_learning_state["is_running"] = False

        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        interval = get_current_interval()
        auto_learning_state["next_run"] = (
            datetime.now(timezone.utc) + timedelta(minutes=interval)
        ).isoformat()


async def run_auto_training():
    """ìë™ ëª¨ë¸ í›ˆë ¨"""
    global auto_learning_state

    try:
        from database.learning_db import get_learning_samples, get_current_weights, save_current_weights
        from services.learning_engine import instant_adjust_weights

        samples = get_learning_samples(limit=1000)

        if len(samples) < 20:
            logger.info(f"[AutoLearn] Not enough samples for training: {len(samples)}")
            return

        current_weights = get_current_weights()
        if not current_weights:
            return

        logger.info(f"[AutoLearn] Starting auto-training with {len(samples)} samples")

        new_weights, info = instant_adjust_weights(
            samples=samples,
            current_weights=current_weights,
            target_accuracy=95.0,
            max_iterations=30,
            learning_rate=0.03,
            momentum=0.9
        )

        initial_accuracy = info.get("initial_accuracy", 0)
        final_accuracy = info.get("final_accuracy", 0)

        # ì •í™•ë„ê°€ í–¥ìƒë˜ì—ˆì„ ë•Œë§Œ ì €ì¥
        if final_accuracy >= initial_accuracy:
            save_current_weights(new_weights)
            logger.info(f"[AutoLearn] Model improved: {initial_accuracy:.1f}% -> {final_accuracy:.1f}%")
        else:
            logger.info(f"[AutoLearn] Model not improved, rollback: {initial_accuracy:.1f}% -> {final_accuracy:.1f}%")

        auto_learning_state["samples_since_last_train"] = 0

    except Exception as e:
        logger.error(f"[AutoLearn] Training failed: {e}")


async def run_daily_intensive_training():
    """ë§¤ì¼ ëŒ€ê·œëª¨ í›ˆë ¨ (ë” ë§ì€ ìƒ˜í”Œ, ë” ë§ì€ ë°˜ë³µ)"""
    global auto_learning_state

    try:
        from database.learning_db import (
            get_learning_samples, get_current_weights, save_current_weights,
            save_training_session, save_weight_history
        )
        from services.learning_engine import instant_adjust_weights
        import uuid

        config = AUTO_LEARNING_CONFIG
        samples = get_learning_samples(limit=config["daily_training_samples"])

        if len(samples) < 100:
            logger.info(f"[DailyTrain] Not enough samples: {len(samples)}")
            return

        current_weights = get_current_weights()
        if not current_weights:
            return

        session_id = f"daily_{uuid.uuid4().hex[:8]}"
        started_at = datetime.now(timezone.utc).isoformat()

        logger.info(f"[DailyTrain] ğŸš€ Starting intensive training with {len(samples)} samples")

        # ë” ë§ì€ ë°˜ë³µ, ë” ì‘ì€ í•™ìŠµë¥ ë¡œ ì„¸ë°€í•œ ì¡°ì •
        new_weights, info = instant_adjust_weights(
            samples=samples,
            current_weights=current_weights,
            target_accuracy=80.0,  # í˜„ì‹¤ì ì¸ ëª©í‘œ (í‚¤ì›Œë“œë³„ ì •í™•ë„ ê³„ì‚° ì‹œ)
            max_iterations=200,    # ë” ë§ì€ ë°˜ë³µ
            learning_rate=0.02,    # ë” ì‘ì€ í•™ìŠµë¥ 
            momentum=0.95          # ë” ë†’ì€ ëª¨ë©˜í…€
        )

        initial_accuracy = info.get("initial_accuracy", 0)
        final_accuracy = info.get("final_accuracy", 0)
        improvement = final_accuracy - initial_accuracy

        completed_at = datetime.now(timezone.utc).isoformat()

        # ê²°ê³¼ ì €ì¥
        if final_accuracy >= initial_accuracy:
            save_current_weights(new_weights)
            save_weight_history(session_id, new_weights, final_accuracy, len(samples))
            logger.info(f"[DailyTrain] âœ… Model improved: {initial_accuracy:.1f}% -> {final_accuracy:.1f}%")
        else:
            logger.warning(f"[DailyTrain] âš ï¸ Model not improved: {initial_accuracy:.1f}% -> {final_accuracy:.1f}%")

        # ì„¸ì…˜ ì €ì¥
        save_training_session(
            session_id=session_id,
            samples_used=len(samples),
            accuracy_before=initial_accuracy,
            accuracy_after=final_accuracy,
            improvement=improvement,
            duration_seconds=info.get("duration_seconds", 0),
            epochs=info.get("iterations", 0),
            learning_rate=0.02,
            started_at=started_at,
            completed_at=completed_at,
            keywords=list(set(s.get('keyword', '') for s in samples[:100])),
            weight_changes=info.get("weight_changes", {})
        )

        auto_learning_state["last_daily_training"] = completed_at
        auto_learning_state["daily_training_accuracy"] = final_accuracy

        logger.info(f"[DailyTrain] ğŸ“Š Results: {initial_accuracy:.1f}% -> {final_accuracy:.1f}% (Î”{improvement:+.1f}%)")

    except Exception as e:
        logger.error(f"[DailyTrain] Training failed: {e}")
        import traceback
        traceback.print_exc()


class AutoLearningScheduler:
    """ìë™ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(self):
        self.running = False
        self.thread = None
        self.loop = None

    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.running:
            logger.info("[AutoLearn] Scheduler already running")
            return

        if not AUTO_LEARNING_CONFIG["enabled"]:
            logger.info("[AutoLearn] Auto learning is disabled in config")
            return

        self.running = True
        auto_learning_state["is_enabled"] = True
        self.thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.thread.start()
        logger.info("[AutoLearn] Scheduler started")

    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.running = False
        auto_learning_state["is_enabled"] = False
        if self.thread:
            self.thread.join(timeout=10)
        logger.info("[AutoLearn] Scheduler stopped")

    def enable(self):
        """í•™ìŠµ í™œì„±í™”"""
        auto_learning_state["is_enabled"] = True
        if not self.running:
            self.start()
        logger.info("[AutoLearn] Learning enabled")

    def disable(self):
        """í•™ìŠµ ë¹„í™œì„±í™” (ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ìœ ì§€)"""
        auto_learning_state["is_enabled"] = False
        logger.info("[AutoLearn] Learning disabled")

    def _run_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„"""
        # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)

        # ì‹œì‘ ì‹œ ì•½ê°„ì˜ ë”œë ˆì´ (ì„œë²„ ì•ˆì •í™” ëŒ€ê¸°)
        time.sleep(60)

        logger.info("[AutoLearn] Starting first learning cycle...")

        last_daily_training_date = None

        while self.running:
            try:
                current_hour = datetime.now(timezone.utc).hour
                current_date = datetime.now(timezone.utc).date()

                # ë§¤ì¼ ëŒ€ê·œëª¨ í›ˆë ¨ ì²´í¬ (ì§€ì •ëœ ì‹œê°„, í•˜ë£¨ í•œ ë²ˆë§Œ)
                if (current_hour == AUTO_LEARNING_CONFIG["daily_training_hour"] and
                    last_daily_training_date != current_date):
                    logger.info("[AutoLearn] ğŸ¯ Starting daily intensive training...")
                    self.loop.run_until_complete(run_daily_intensive_training())
                    last_daily_training_date = current_date

                if auto_learning_state["is_enabled"]:
                    # ë¹„ë™ê¸° í•™ìŠµ ì‚¬ì´í´ ì‹¤í–‰
                    self.loop.run_until_complete(run_single_learning_cycle())

                # ë‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ ëŒ€ê¸°
                interval = get_current_interval()

                # 1ë¶„ ë‹¨ìœ„ë¡œ ì²´í¬í•˜ë©´ì„œ ëŒ€ê¸° (ë¹ ë¥¸ ì¢…ë£Œ ëŒ€ì‘)
                wait_seconds = interval * 60
                for _ in range(wait_seconds // 60):
                    if not self.running:
                        break
                    time.sleep(60)

                # ë‚¨ì€ ì‹œê°„ ëŒ€ê¸°
                remaining = wait_seconds % 60
                if remaining > 0 and self.running:
                    time.sleep(remaining)

            except Exception as e:
                logger.error(f"[AutoLearn] Scheduler error: {e}")
                time.sleep(300)  # ì—ëŸ¬ ì‹œ 5ë¶„ ëŒ€ê¸°

        self.loop.close()


def get_auto_learning_status() -> Dict:
    """ìë™ í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
    return {
        "config": AUTO_LEARNING_CONFIG,
        "state": {
            **auto_learning_state,
            "errors_count": len(auto_learning_state["errors"]),
            "recent_errors": auto_learning_state["errors"][-5:] if auto_learning_state["errors"] else []
        }
    }


def update_auto_learning_config(updates: Dict) -> Dict:
    """ìë™ í•™ìŠµ ì„¤ì • ì—…ë°ì´íŠ¸"""
    global AUTO_LEARNING_CONFIG

    allowed_keys = [
        "enabled", "interval_minutes", "keywords_per_cycle",
        "blogs_per_keyword", "delay_between_keywords", "delay_between_blogs",
        "auto_train_threshold", "quiet_hours_start", "quiet_hours_end"
    ]

    for key, value in updates.items():
        if key in allowed_keys:
            AUTO_LEARNING_CONFIG[key] = value

    return AUTO_LEARNING_CONFIG


# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
auto_learning_scheduler = AutoLearningScheduler()
