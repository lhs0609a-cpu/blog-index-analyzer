"""
ì»¤ë®¤ë‹ˆí‹° ì½˜í…ì¸  ìë™ ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬
- ì„œë²„ ë¶€í•˜ ìµœì†Œí™”ë¥¼ ìœ„í•œ ë¶„ì‚° ì‹¤í–‰
- ìì—°ìŠ¤ëŸ¬ìš´ ì‹œê°„ëŒ€ë³„ ì½˜í…ì¸  ìƒì„±
- ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
"""
import asyncio
import random
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

logger = logging.getLogger(__name__)


# ============ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ============

class ContentSchedulerConfig:
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"""

    # ì¼ì¼ ìƒì„±ëŸ‰ (ì„œë²„ ë¶€í•˜ ê³ ë ¤)
    DAILY_POSTS_MIN = 20
    DAILY_POSTS_MAX = 50

    DAILY_COMMENTS_MIN = 100
    DAILY_COMMENTS_MAX = 300

    # ìƒì„± ì‹œê°„ëŒ€ (í•œêµ­ì‹œê°„ ê¸°ì¤€)
    # ì—¬ëŸ¬ ì‹œê°„ëŒ€ì— ë¶„ì‚°í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ
    GENERATION_HOURS = [
        (7, 9),    # ì˜¤ì „ ì¶œê·¼ ì‹œê°„
        (10, 12),  # ì˜¤ì „
        (13, 15),  # ì ì‹¬ í›„
        (16, 18),  # ì˜¤í›„
        (19, 21),  # ì €ë…
        (22, 24),  # ë°¤
    ]

    # ê° ì‹œê°„ëŒ€ë³„ ìƒì„± ë¹„ìœ¨
    TIME_WEIGHTS = {
        (7, 9): 0.10,
        (10, 12): 0.15,
        (13, 15): 0.15,
        (16, 18): 0.15,
        (19, 21): 0.25,  # ì €ë… í”¼í¬
        (22, 24): 0.20,
    }

    # ì£¼ë§ ê°€ì¤‘ì¹˜ (í‰ì¼ë³´ë‹¤ í™œë™ ë§ìŒ)
    WEEKEND_MULTIPLIER = 1.3


# ============ ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤ ============

class ContentScheduler:
    """ì½˜í…ì¸  ìë™ ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(self):
        self.scheduler = AsyncIOScheduler(timezone="Asia/Seoul")
        self.config = ContentSchedulerConfig()
        self.is_running = False
        self.stats = {
            "total_posts_generated": 0,
            "total_comments_generated": 0,
            "last_run": None,
            "errors": [],
        }

    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.is_running:
            logger.warning("Scheduler is already running")
            return

        # 1. ë§¤ì‹œê°„ ì½˜í…ì¸  ìƒì„± (ëœë¤ ì§€ì—°ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ)
        self.scheduler.add_job(
            self._hourly_content_generation,
            IntervalTrigger(hours=1),
            id="hourly_content",
            name="Hourly Content Generation",
            replace_existing=True,
        )

        # 2. ë§¤ì¼ ìì •ì— í†µê³„ ë¦¬ì…‹ ë° ì¼ì¼ ê³„íš ìˆ˜ë¦½
        self.scheduler.add_job(
            self._daily_planning,
            CronTrigger(hour=0, minute=5),
            id="daily_planning",
            name="Daily Planning",
            replace_existing=True,
        )

        # 3. ê¸°ì¡´ ê²Œì‹œê¸€ì— ëŒ“ê¸€ ì¶”ê°€ (4ì‹œê°„ë§ˆë‹¤)
        self.scheduler.add_job(
            self._add_engagement,
            IntervalTrigger(hours=4),
            id="add_engagement",
            name="Add Engagement to Posts",
            replace_existing=True,
        )

        # 4. ì£¼ê°„ ì¸ê¸°ê¸€ ìƒì„± (ì¼ìš”ì¼ ì €ë…)
        self.scheduler.add_job(
            self._weekly_highlight,
            CronTrigger(day_of_week="sun", hour=20, minute=0),
            id="weekly_highlight",
            name="Weekly Highlight Generation",
            replace_existing=True,
        )

        self.scheduler.start()
        self.is_running = True
        logger.info("Content Scheduler started")

    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        if self.scheduler.running:
            self.scheduler.shutdown()
            self.is_running = False
            logger.info("Content Scheduler stopped")

    async def _hourly_content_generation(self):
        """ë§¤ì‹œê°„ ì½˜í…ì¸  ìƒì„±"""
        try:
            now = datetime.now()
            current_hour = now.hour

            # í˜„ì¬ ì‹œê°„ëŒ€ í™•ì¸
            time_slot = None
            for slot in self.config.GENERATION_HOURS:
                if slot[0] <= current_hour < slot[1]:
                    time_slot = slot
                    break

            if not time_slot:
                logger.debug(f"Skipping content generation at hour {current_hour}")
                return

            # ì´ ì‹œê°„ëŒ€ì— ìƒì„±í•  ì–‘ ê³„ì‚°
            weight = self.config.TIME_WEIGHTS.get(time_slot, 0.1)

            # ì£¼ë§ ê°€ì¤‘ì¹˜
            if now.weekday() >= 5:
                weight *= self.config.WEEKEND_MULTIPLIER

            # ì‹œê°„ë‹¹ ìƒì„±ëŸ‰ (ì¼ì¼ ì´ëŸ‰ì˜ ì¼ë¶€)
            daily_posts = random.randint(
                self.config.DAILY_POSTS_MIN,
                self.config.DAILY_POSTS_MAX
            )
            hourly_posts = max(1, int(daily_posts * weight / len(self.config.GENERATION_HOURS)))

            # ëœë¤ ì§€ì—° (0~30ë¶„) - ì •í™•íˆ ì •ì‹œì— ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡
            delay = random.randint(0, 30 * 60)
            await asyncio.sleep(delay)

            # ì½˜í…ì¸  ìƒì„±
            from services.natural_content_generator import generate_daily_natural_content

            result = generate_daily_natural_content(
                posts_count=(max(1, hourly_posts - 2), hourly_posts + 2),
                comments_per_post=(2, 8),
            )

            self.stats["total_posts_generated"] += result["posts_created"]
            self.stats["total_comments_generated"] += result["comments_created"]
            self.stats["last_run"] = now.isoformat()

            logger.info(
                f"Hourly content generated: {result['posts_created']} posts, "
                f"{result['comments_created']} comments"
            )

        except Exception as e:
            logger.error(f"Hourly content generation failed: {e}")
            self.stats["errors"].append({
                "time": datetime.now().isoformat(),
                "error": str(e),
                "job": "hourly_content"
            })

    async def _daily_planning(self):
        """ë§¤ì¼ ìì •ì— ì‹¤í–‰ - ì¼ì¼ ê³„íš ìˆ˜ë¦½"""
        try:
            # ì–´ì œ í†µê³„ ë¡œê¹…
            logger.info(
                f"Daily stats: {self.stats['total_posts_generated']} posts, "
                f"{self.stats['total_comments_generated']} comments"
            )

            # í†µê³„ ë¦¬ì…‹
            self.stats["total_posts_generated"] = 0
            self.stats["total_comments_generated"] = 0
            self.stats["errors"] = []

            logger.info("Daily planning completed")

        except Exception as e:
            logger.error(f"Daily planning failed: {e}")

    async def _add_engagement(self):
        """ê¸°ì¡´ ê²Œì‹œê¸€ì— í™œë™ ì¶”ê°€"""
        try:
            # ëœë¤ ì§€ì—°
            delay = random.randint(0, 20 * 60)
            await asyncio.sleep(delay)

            from services.natural_content_generator import add_comments_to_existing_posts

            result = add_comments_to_existing_posts(
                max_posts=random.randint(10, 25),
                comments_per_post=(1, 4),
            )

            self.stats["total_comments_generated"] += result["comments_added"]

            logger.info(
                f"Engagement added: {result['comments_added']} comments to "
                f"{result['posts_updated']} posts"
            )

        except Exception as e:
            logger.error(f"Add engagement failed: {e}")
            self.stats["errors"].append({
                "time": datetime.now().isoformat(),
                "error": str(e),
                "job": "add_engagement"
            })

    async def _weekly_highlight(self):
        """ì£¼ê°„ í•˜ì´ë¼ì´íŠ¸ ê²Œì‹œê¸€ ìƒì„±"""
        try:
            from services.natural_content_generator import (
                generate_virtual_user, generate_natural_post
            )
            from database.community_db import get_db_connection
            import json

            conn = get_db_connection()
            cursor = conn.cursor()

            # ê¸ˆì£¼ ì¸ê¸° í‚¤ì›Œë“œ ì¡°íšŒ
            cursor.execute("""
                SELECT keyword, search_count
                FROM keyword_trends
                WHERE date >= date('now', '-7 days')
                ORDER BY search_count DESC
                LIMIT 5
            """)
            trending = cursor.fetchall()

            # ì£¼ê°„ ì •ë¦¬ ê²Œì‹œê¸€ ìƒì„±
            user = generate_virtual_user()
            now = datetime.now()

            if trending:
                keywords = [row["keyword"] for row in trending[:3]]
                keyword_text = ", ".join(keywords)

                content = f"""ì´ë²ˆì£¼ ì¸ê¸° í‚¤ì›Œë“œ ì •ë¦¬í•´ë´„

{keyword_text} ì´ëŸ° í‚¤ì›Œë“œë“¤ì´ í•«í–ˆë„¤ìš”

ë‹¤ë“¤ ì–´ë–¤ í‚¤ì›Œë“œë¡œ ê¸€ ì“°ê³  ê³„ì„¸ìš”?
ê³µìœ í•´ì£¼ì„¸ìš”~"""

            else:
                content = """ì´ë²ˆì£¼ë„ ìˆ˜ê³ í•˜ì…¨ì–´ìš”!

ë‹¤ë“¤ ë¸”ë¡œê·¸ ì—´ì‹¬íˆ í•˜ê³  ê³„ì‹ ê°€ìš”?
ë‹¤ìŒì£¼ë„ í™”ì´íŒ…ì…ë‹ˆë‹¤ ğŸ’ª"""

            cursor.execute("""
                INSERT INTO posts (user_id, user_name, title, content, category, tags, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                user.id,
                user.name,
                "ì´ë²ˆì£¼ ë¸”ë¡œê·¸ ì–´ë• ì–´ìš”?",
                content,
                "free",
                json.dumps(["ì£¼ê°„ì •ë¦¬", "ì†Œí†µ"]),
                now.isoformat()
            ))

            conn.commit()
            conn.close()

            logger.info("Weekly highlight post created")

        except Exception as e:
            logger.error(f"Weekly highlight failed: {e}")

    def get_status(self) -> Dict:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
        jobs = []
        if self.scheduler.running:
            for job in self.scheduler.get_jobs():
                jobs.append({
                    "id": job.id,
                    "name": job.name,
                    "next_run": job.next_run_time.isoformat() if job.next_run_time else None,
                })

        return {
            "is_running": self.is_running,
            "jobs": jobs,
            "stats": self.stats,
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_scheduler_instance: Optional[ContentScheduler] = None


def get_scheduler() -> ContentScheduler:
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _scheduler_instance
    if _scheduler_instance is None:
        _scheduler_instance = ContentScheduler()
    return _scheduler_instance


# ============ ìˆ˜ë™ ì‹¤í–‰ í•¨ìˆ˜ ============

async def run_manual_generation(
    posts_count: int = 10,
    add_comments: bool = True,
) -> Dict:
    """ìˆ˜ë™ìœ¼ë¡œ ì½˜í…ì¸  ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
    from services.natural_content_generator import (
        generate_daily_natural_content,
        add_comments_to_existing_posts,
    )

    result = {
        "posts_created": 0,
        "comments_created": 0,
        "comments_added_to_existing": 0,
    }

    # ìƒˆ ê²Œì‹œê¸€ ìƒì„±
    gen_result = generate_daily_natural_content(
        posts_count=(posts_count, posts_count + 5),
        comments_per_post=(3, 10),
    )
    result["posts_created"] = gen_result["posts_created"]
    result["comments_created"] = gen_result["comments_created"]

    # ê¸°ì¡´ ê²Œì‹œê¸€ì— ëŒ“ê¸€ ì¶”ê°€
    if add_comments:
        engagement_result = add_comments_to_existing_posts(
            max_posts=15,
            comments_per_post=(1, 3),
        )
        result["comments_added_to_existing"] = engagement_result["comments_added"]

    return result


# ============ ëŒ€ëŸ‰ ì´ˆê¸° ë°ì´í„° ìƒì„± (ì ì§„ì ) ============

async def generate_initial_data_gradually(
    target_posts: int = 10000,
    batch_size: int = 100,
    delay_between_batches: float = 1.0,
) -> Dict:
    """ì„œë²„ ë¶€í•˜ ìµœì†Œí™”í•˜ë©° ëŒ€ëŸ‰ ë°ì´í„° ì ì§„ ìƒì„±"""
    from services.natural_content_generator import (
        generate_natural_post,
        generate_virtual_user,
        generate_contextual_comment,
        generate_reply,
    )
    from database.community_db import get_db_connection
    import json

    logger.info(f"Starting gradual data generation: {target_posts} posts")

    total_posts = 0
    total_comments = 0

    # ê¸°ê°„ ë¶„í¬ (ìµœê·¼ 6ê°œì›”)
    now = datetime.now()

    while total_posts < target_posts:
        conn = get_db_connection()
        cursor = conn.cursor()

        batch_posts = min(batch_size, target_posts - total_posts)

        for _ in range(batch_posts):
            # ëœë¤ ì‹œê°„ (ìµœê·¼ 6ê°œì›” ë‚´, ìµœê·¼ì— ê°€ì¤‘ì¹˜)
            days_ago = min(int(random.expovariate(1/30)), 180)
            post_time = now - timedelta(
                days=days_ago,
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            # ê²Œì‹œê¸€ ìƒì„±
            user = generate_virtual_user()
            post = generate_natural_post(user)

            cursor.execute("""
                INSERT INTO posts (user_id, user_name, title, content, category, tags, views, likes, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                post["user_id"],
                post["user_name"],
                post["title"],
                post["content"],
                post["category"],
                json.dumps(post.get("tags", [])),
                random.randint(10, 500),
                random.randint(0, 30),
                post_time.isoformat()
            ))

            post_id = cursor.lastrowid
            total_posts += 1

            # ëŒ“ê¸€ ìƒì„± (ê²Œì‹œê¸€ë‹¹ 3~15ê°œ)
            num_comments = random.randint(3, 15)

            comment_ids = []
            for j in range(num_comments):
                commenter = generate_virtual_user()
                comment_text = generate_contextual_comment(post, commenter)

                comment_time = post_time + timedelta(
                    hours=random.randint(1, 168)
                )
                if comment_time > now:
                    comment_time = now - timedelta(minutes=random.randint(1, 60))

                cursor.execute("""
                    INSERT INTO post_comments (post_id, user_id, user_name, content, created_at)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    post_id,
                    commenter.id,
                    commenter.name,
                    comment_text,
                    comment_time.isoformat()
                ))

                comment_id = cursor.lastrowid
                comment_ids.append((comment_id, comment_text, commenter))
                total_comments += 1

                # ëŒ€ëŒ“ê¸€ (25% í™•ë¥ )
                if random.random() < 0.25:
                    reply = generate_reply(comment_text, user, user)
                    if reply:
                        reply_time = comment_time + timedelta(minutes=random.randint(5, 120))
                        if reply_time > now:
                            reply_time = now - timedelta(minutes=random.randint(1, 30))

                        cursor.execute("""
                            INSERT INTO post_comments (post_id, user_id, user_name, content, parent_id, created_at)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (
                            post_id,
                            user.id,
                            user.name,
                            reply,
                            comment_id,
                            reply_time.isoformat()
                        ))
                        total_comments += 1

            # ëŒ“ê¸€ ìˆ˜ ì—…ë°ì´íŠ¸
            cursor.execute("""
                UPDATE posts SET comments_count = (
                    SELECT COUNT(*) FROM post_comments WHERE post_id = ? AND is_deleted = FALSE
                ) WHERE id = ?
            """, (post_id, post_id))

        conn.commit()
        conn.close()

        logger.info(f"Progress: {total_posts}/{target_posts} posts, {total_comments} comments")

        # ë°°ì¹˜ ê°„ ë”œë ˆì´ (ì„œë²„ ë¶€í•˜ ë¶„ì‚°)
        await asyncio.sleep(delay_between_batches)

    return {
        "posts_created": total_posts,
        "comments_created": total_comments,
        "message": "Initial data generation completed"
    }
