"""
ì•ˆì „ í‚¤ì›Œë“œ ì„ ë³„ ì‹œìŠ¤í…œ (Safe Keyword Selector)

ëª©í‘œ: "ìƒìœ„ë…¸ì¶œì´ ì•ˆì „í•˜ê²Œ ë  í‚¤ì›Œë“œ"ë§Œ ì„ ë³„

í”¼ë“œë°± ë°˜ì˜:
- 7ìœ„ ì´í•˜ ì˜ˆì¸¡ í‚¤ì›Œë“œ â†’ ì‹¤ì œ 10ìœ„ê¶Œ ë°– (ì „êµ­ í‚¤ì›Œë“œ)
- 1ìœ„ ì˜ˆì¸¡ ì§€ì—­ í‚¤ì›Œë“œ â†’ ì‹¤ì œ 1-2ìœ„ (ì •í™•í•¨)

í•´ê²°ì±…:
1. ì „êµ­ í‚¤ì›Œë“œì— ì•ˆì „ ë§ˆì§„ +2~3 ì ìš©
2. 6ìœ„ ì´ë‚´ ì˜ˆì¸¡ë§Œ "ì§„ì… ê°€ëŠ¥"ìœ¼ë¡œ íŒì •
3. ì ìˆ˜ ì—¬ìœ ë„, ê²½ìŸ ì•ˆì •ì„± ë“± ì¢…í•© í‰ê°€
"""

import re
import math
import logging
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
import numpy as np

from services.competition_analyzer import (
    competition_analyzer, CompetitionAnalysisResult,
    CompetitionDifficulty, ContentRelevanceScore,
    FreshnessScore, EngagementScore, BlogScoreAnalysis
)

logger = logging.getLogger(__name__)


# ==============================================
# ìƒìˆ˜ ì •ì˜
# ==============================================

class KeywordScope(str, Enum):
    """í‚¤ì›Œë“œ ë²”ìœ„"""
    LOCAL = "ì§€ì—­"      # ì§€ì—­ í‚¤ì›Œë“œ (ì˜ˆ: ê°•ë‚¨ì—­ í•œì˜ì›)
    REGIONAL = "ê´‘ì—­"   # ê´‘ì—­ í‚¤ì›Œë“œ (ì˜ˆ: ì„œìš¸ í•œì˜ì›)
    NATIONAL = "ì „êµ­"   # ì „êµ­ í‚¤ì›Œë“œ (ì˜ˆ: í—ˆë¦¬ë””ìŠ¤í¬ ì¹˜ë£Œ)
    BRAND = "ë¸Œëœë“œ"    # ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ (ì˜ˆ: ë¡œë‹´í•œì˜ì›) - ì‹ ê·œ ì¶”ê°€


class SearchIntent(str, Enum):
    """ê²€ìƒ‰ ì˜ë„ (Search Intent)"""
    NAVIGATIONAL = "ë„¤ë¹„ê²Œì´ì…˜"  # íŠ¹ì • ë¸Œëœë“œ/ë³‘ì› ì°¾ê¸° (ì˜ˆ: ë¡œë‹´í•œì˜ì›)
    INFORMATIONAL = "ì •ë³´í˜•"     # ì •ë³´ íƒìƒ‰ (ì˜ˆ: í—ˆë¦¬ë””ìŠ¤í¬ ì¦ìƒ)
    TRANSACTIONAL = "ê±°ë˜í˜•"     # ì˜ˆì•½/êµ¬ë§¤ ì˜ë„ (ì˜ˆ: ê°•ë‚¨ í”¼ë¶€ê³¼ ì˜ˆì•½)
    LOCAL_SEARCH = "ì§€ì—­íƒìƒ‰"    # ì§€ì—­ ë‚´ ì„œë¹„ìŠ¤ íƒìƒ‰ (ì˜ˆ: í™ëŒ€ ì—¬ë“œë¦„)


class SafetyGrade(str, Enum):
    """ì•ˆì „ ë“±ê¸‰"""
    VERY_SAFE = "ë§¤ìš°ì•ˆì „"     # 90%+ í™•ë¥ ë¡œ ìƒìœ„ë…¸ì¶œ
    SAFE = "ì•ˆì „"              # 70-89% í™•ë¥ 
    MODERATE = "ë³´í†µ"          # 50-69% í™•ë¥ 
    RISKY = "ìœ„í—˜"             # 30-49% í™•ë¥ 
    VERY_RISKY = "ë§¤ìš°ìœ„í—˜"    # 30% ë¯¸ë§Œ


class RecommendationType(str, Enum):
    """ì¶”ì²œ ìœ í˜•"""
    STRONGLY_RECOMMEND = "ê°•ë ¥ì¶”ì²œ"    # ë°”ë¡œ ì‘ì„±í•´ë„ ë¨
    RECOMMEND = "ì¶”ì²œ"                  # ì¶”ì²œí•˜ì§€ë§Œ ì½˜í…ì¸  í€„ë¦¬í‹° í•„ìš”
    CONDITIONAL = "ì¡°ê±´ë¶€ì¶”ì²œ"          # ì¡°ê±´ ì¶©ì¡±ì‹œ ê°€ëŠ¥
    NOT_RECOMMEND = "ë¹„ì¶”ì²œ"            # í˜„ì¬ ë¸”ë¡œê·¸ë¡œëŠ” ì–´ë ¤ì›€
    AVOID = "íšŒí”¼ê¶Œì¥"                  # ì‹œê°„ ë‚­ë¹„ ê°€ëŠ¥ì„±


# ì§€ì—­ í‚¤ì›Œë“œ íŒ¨í„´
LOCAL_PATTERNS = {
    # êµ¬/ë™/ì—­ ë‹¨ìœ„ + ì‹œì„¤
    'patterns': [
        r'^(ê°•ë‚¨|ì„œì´ˆ|ì†¡íŒŒ|ê°•ë™|ê°•ì„œ|ë§ˆí¬|ì˜ë“±í¬|ìš©ì‚°|ì„±ë¶|ë…¸ì›|'
        r'ë¶„ë‹¹|íŒêµ|ì¼ì‚°|ìˆ˜ì›|ì•ˆì–‘|ë¶€ì²œ|ì¸ì²œ|ì˜ì •ë¶€|ìœ„ë¡€|'
        r'í•´ìš´ëŒ€|ì„œë©´|ë™ë˜|ë‚¨í¬ë™|ì„¼í…€).*(ë³‘ì›|ì˜ì›|í•œì˜ì›|ì¹˜ê³¼|í”¼ë¶€ê³¼|í´ë¦¬ë‹‰)',

        r'.*ì—­\s*(ë³‘ì›|ì˜ì›|í•œì˜ì›|ì¹˜ê³¼|í”¼ë¶€ê³¼)',
        r'.*ë™\s*(ë³‘ì›|ì˜ì›|í•œì˜ì›)',
        r'.*êµ¬\s*(ë³‘ì›|ì˜ì›)',
    ],
    # ì§€ì—­ëª… í‚¤ì›Œë“œ
    'prefixes': [
        'ê°•ë‚¨', 'ì„œì´ˆ', 'ì†¡íŒŒ', 'ê°•ë™', 'ê°•ì„œ', 'ë§ˆí¬', 'ì˜ë“±í¬', 'ìš©ì‚°',
        'ì„±ë¶', 'ë…¸ì›', 'ë¶„ë‹¹', 'íŒêµ', 'ì¼ì‚°', 'ìˆ˜ì›', 'ì•ˆì–‘', 'ë¶€ì²œ',
        'ì¸ì²œ', 'ì˜ì •ë¶€', 'ìœ„ë¡€', 'í•´ìš´ëŒ€', 'ì„œë©´', 'ë™ë˜', 'ë‚¨í¬ë™', 'ì„¼í…€',
        'í™ëŒ€', 'ì‹ ì´Œ', 'ì´ëŒ€', 'ê±´ëŒ€', 'ì ì‹¤', 'ì‚¼ì„±', 'ì—­ì‚¼', 'ì„ ë¦‰',
    ],
    # ì˜ë£Œ/ë¯¸ìš© ì„œë¹„ìŠ¤ í‚¤ì›Œë“œ (ì§€ì—­ëª…ê³¼ ê²°í•© ì‹œ ì§€ì—­ í‚¤ì›Œë“œë¡œ ì¸ì‹)
    'medical_services': [
        # í”¼ë¶€ê³¼/ë¯¸ìš© ê´€ë ¨
        'ì—¬ë“œë¦„', 'í‰í„°', 'ëª¨ê³µ', 'ê¸°ë¯¸', 'ì£¼ê·¼ê¹¨', 'ì¡í‹°', 'í”¼ë¶€ê´€ë¦¬', 'í”¼ë¶€ì‹œìˆ ',
        'ë ˆì´ì €', 'ë¦¬í”„íŒ…', 'ë³´í†¡ìŠ¤', 'í•„ëŸ¬', 'ì˜ë ì„±í˜•', 'í”¼ë¶€ì¬ìƒ', 'ì—¬ë“œë¦„í‰í„°',
        'ìƒ‰ì†Œì¹¨ì°©', 'í™ì¡°', 'ì•„í† í”¼', 'ê±´ì„ ', 'ë‘í”¼', 'íƒˆëª¨',
        # ë‹¤ì´ì–´íŠ¸/ì²´í˜• ê´€ë ¨
        'ë‹¤ì´ì–´íŠ¸', 'ë‹¤ì´ì–´íŠ¸í•œì•½', 'ë¹„ë§Œ', 'ì²´í˜•ê´€ë¦¬', 'ì§€ë°©ë¶„í•´', 'ìŠ¬ë¦¬ë°',
        'í•œë°©ë‹¤ì´ì–´íŠ¸', 'ì‹ì´ì¡°ì ˆ', 'ì²´ì¤‘ê°ëŸ‰',
        # í•œì˜ì› ê´€ë ¨
        'í•œì•½', 'ì¹¨', 'ëœ¸', 'ë¶€í•­', 'ì¶”ë‚˜', 'í•œë°©', 'ë³´ì•½', 'ê³µì§„ë‹¨', 'ê²½ì˜¥ê³ ',
        'ì‚¬ìƒì²´ì§ˆ', 'ì²´ì§ˆ', 'í•œë°©ì¹˜ë£Œ',
        # í†µì¦/ì¬í™œ ê´€ë ¨
        'í†µì¦', 'ë””ìŠ¤í¬', 'í—ˆë¦¬', 'ëª©', 'ì–´ê¹¨', 'ë¬´ë¦', 'ê´€ì ˆ', 'ì²™ì¶”', 'ì²´í˜•êµì •',
        'ìì„¸êµì •', 'ë„ìˆ˜ì¹˜ë£Œ', 'ë¬¼ë¦¬ì¹˜ë£Œ', 'ì¬í™œ',
        # ê¸°íƒ€ ì˜ë£Œ ì„œë¹„ìŠ¤
        'êµì •', 'ì„í”Œë€íŠ¸', 'ì¹˜ì•„', 'ë¼ì‹', 'ë¼ì„¹', 'ì‹œë ¥êµì •', 'ëˆˆ', 'ì½”', 'ì•ˆë©´',
        'ì„±í˜•', 'ìŒêº¼í’€', 'ì½”ì„±í˜•', 'ì§€ë°©í¡ì…', 'ê°€ìŠ´ì„±í˜•',
        # ì‚°ë¶€ì¸ê³¼/ë¹„ë‡¨ê¸°ê³¼ ê´€ë ¨
        'ì‚°ë¶€ì¸ê³¼', 'ì„ì‹ ', 'ì¶œì‚°', 'ë‚œì„', 'ë¹„ë‡¨ê¸°ê³¼', 'ë‚¨ì„±', 'ì—¬ì„±',
        # ê²€ì§„ ê´€ë ¨
        'ê±´ê°•ê²€ì§„', 'ì¢…í•©ê²€ì§„', 'ë‚´ì‹œê²½', 'MRI', 'CT',
    ]
}

# ê´‘ì—­ í‚¤ì›Œë“œ íŒ¨í„´
REGIONAL_PATTERNS = {
    'prefixes': [
        'ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ëŒ€ì „', 'ê´‘ì£¼', 'ìš¸ì‚°', 'ì„¸ì¢…',
        'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼'
    ]
}

# ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ ê°ì§€ íŒ¨í„´
BRAND_PATTERNS = {
    # ë³‘ì›/ì˜ì› ì‹œì„¤ ì ‘ë¯¸ì‚¬
    'facility_suffixes': [
        'í•œì˜ì›', 'ì˜ì›', 'ë³‘ì›', 'ì¹˜ê³¼', 'í´ë¦¬ë‹‰', 'ì„¼í„°', 'í”¼ë¶€ê³¼', 'ì•ˆê³¼',
        'ì´ë¹„ì¸í›„ê³¼', 'ì •í˜•ì™¸ê³¼', 'ë‚´ê³¼', 'ì™¸ê³¼', 'ì‚°ë¶€ì¸ê³¼', 'ë¹„ë‡¨ê¸°ê³¼',
        'ì •ì‹ ê±´ê°•ì˜í•™ê³¼', 'ì‹ ê²½ê³¼', 'ì¬í™œì˜í•™ê³¼', 'ì†Œì•„ê³¼', 'ì„±í˜•ì™¸ê³¼',
    ],
    # ì§€ì—­ëª…ì´ ì•„ë‹Œ ì¼ë°˜ì ì¸ ë¸Œëœë“œëª… ì ‘ë‘ì‚¬ íŒ¨í„´ (2ê¸€ì ì´ìƒì˜ í•œê¸€)
    # ì´ íŒ¨í„´ì— í•´ë‹¹í•˜ë©´ì„œ facility_suffixë¡œ ëë‚˜ë©´ ë¸Œëœë“œ í‚¤ì›Œë“œ
    'exclude_prefixes': [
        # ì§€ì—­ëª…ì€ ì œì™¸ (LOCAL_PATTERNSê³¼ REGIONAL_PATTERNSì˜ prefixes)
    ],
    # ë¸Œëœë“œ í‚¤ì›Œë“œë¡œ í™•ì •í•˜ëŠ” íŠ¹ìˆ˜ íŒ¨í„´
    'brand_indicators': [
        # "OOì˜OO" í˜•íƒœ (ì˜ˆ: ë°”ë¥¸ëª¸ì˜ì›, ì´ìœì´ì¹˜ê³¼)
        r'^[ê°€-í£]{2,}ì˜[ê°€-í£]{2,}(ì˜ì›|ì¹˜ê³¼|í•œì˜ì›|ë³‘ì›)$',
        # ì˜ë¬¸ í¬í•¨ (ì˜ˆ: Dr.Kimì¹˜ê³¼)
        r'^[A-Za-z]+.*?(ì˜ì›|ì¹˜ê³¼|í•œì˜ì›|ë³‘ì›)$',
        # ìˆ«ì í¬í•¨ (ì˜ˆ: 365í•œì˜ì›)
        r'^[0-9]+.*?(ì˜ì›|ì¹˜ê³¼|í•œì˜ì›|ë³‘ì›)$',
    ]
}


@dataclass
class SafetyAnalysis:
    """ì•ˆì „ ë¶„ì„ ê²°ê³¼"""
    keyword: str
    scope: KeywordScope

    # ì˜ˆì¸¡ ì •ë³´
    raw_predicted_rank: int          # ì›ë³¸ ì˜ˆì¸¡ ìˆœìœ„
    safety_margin: int               # ì ìš©ëœ ì•ˆì „ ë§ˆì§„
    adjusted_rank: int               # ë³´ì •ëœ ìˆœìœ„

    # ì ìˆ˜ ë¶„ì„
    my_score: float
    top10_scores: List[float]
    top10_avg: float
    top10_min: float
    top10_std: float                 # í‘œì¤€í¸ì°¨ (ê²½ìŸ ì•ˆì •ì„±)
    score_gap: float                 # ë‚´ ì ìˆ˜ - ìµœì € ì ìˆ˜
    score_buffer: float              # ì ìˆ˜ ì—¬ìœ ë„ (%)

    # ê²½ìŸ ë¶„ì„
    influencer_count: int
    high_scorer_count: int           # 70ì  ì´ìƒ ë¸”ë¡œê·¸ ìˆ˜

    # ì•ˆì „ ì§€ìˆ˜
    safety_score: float              # 0-100
    safety_grade: SafetyGrade
    confidence: float                # ì˜ˆì¸¡ ì‹ ë¢°ë„ (%)

    # ì¶”ì²œ
    recommendation: RecommendationType
    reasons: List[str]
    tips: List[str]

    # ê²€ìƒ‰ëŸ‰
    search_volume: int = 0

    # ê²½ê³ 
    warnings: List[str] = field(default_factory=list)

    # 5ìœ„ ë³´ì¥ ì—¬ë¶€
    is_guaranteed_top5: bool = False
    guaranteed_top5_reasons: List[str] = field(default_factory=list)

    # ê²€ìƒ‰ ì˜ë„ ë¶„ì„ (ì‹ ê·œ ì¶”ê°€)
    search_intent: SearchIntent = SearchIntent.INFORMATIONAL
    is_brand_keyword: bool = False           # ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ ì—¬ë¶€
    has_official_blog: bool = False          # ê³µì‹ ë¸”ë¡œê·¸ ì¡´ì¬ ì—¬ë¶€
    official_blog_rank: Optional[int] = None  # ê³µì‹ ë¸”ë¡œê·¸ ìˆœìœ„

    # 2025-01 ì¶”ê°€: ì •ë°€ ê²½ìŸë„ ë¶„ì„
    competition_analysis: Optional[CompetitionAnalysisResult] = None
    content_relevance_score: float = 0.0     # ì½˜í…ì¸  ì í•©ë„ ì ìˆ˜
    freshness_score: float = 0.0             # ìµœì‹ ì„± ì ìˆ˜
    engagement_score: float = 0.0            # ì°¸ì—¬ë„ ì ìˆ˜
    total_competition_score: float = 0.0     # ì¢…í•© ê²½ìŸë„ ì ìˆ˜
    competition_difficulty: str = "ë³´í†µ"      # ê²½ìŸ ë‚œì´ë„


class SafeKeywordSelector:
    """ì•ˆì „ í‚¤ì›Œë“œ ì„ ë³„ê¸°"""

    def __init__(self):
        self._compile_patterns()

    def _compile_patterns(self):
        """ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼"""
        self._local_patterns = [
            re.compile(p, re.IGNORECASE)
            for p in LOCAL_PATTERNS['patterns']
        ]
        # ë¸Œëœë“œ íŒ¨í„´ ì»´íŒŒì¼
        self._brand_patterns = [
            re.compile(p, re.IGNORECASE)
            for p in BRAND_PATTERNS.get('brand_indicators', [])
        ]

    # ==============================================
    # ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ ê°ì§€
    # ==============================================

    def is_brand_keyword(self, keyword: str) -> bool:
        """
        í‚¤ì›Œë“œê°€ ë¸Œëœë“œ/ë³‘ì›ëª…ì¸ì§€ ê°ì§€

        ë¸Œëœë“œ í‚¤ì›Œë“œ ì˜ˆ: ë¡œë‹´í•œì˜ì›, ë°”ë¥¸ì •í˜•ì™¸ê³¼, ì˜ˆì¨ì£¼ì˜ì¹˜ê³¼
        - ì§€ì—­ëª…ì´ ì•„ë‹Œ ê³ ìœ ëª…ì‚¬ + ì‹œì„¤ ì ‘ë¯¸ì‚¬ ì¡°í•©
        - ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •ë˜ì–´ ì¼ë°˜ ë¸”ë¡œê±°ê°€ ì§„ì…í•˜ê¸° ì–´ë ¤ì›€

        Returns:
            True if ë¸Œëœë“œ í‚¤ì›Œë“œ
        """
        keyword_lower = keyword.lower().strip()

        # 1. ì‹œì„¤ ì ‘ë¯¸ì‚¬ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
        has_facility_suffix = False
        matched_suffix = None
        for suffix in BRAND_PATTERNS['facility_suffixes']:
            if keyword_lower.endswith(suffix):
                has_facility_suffix = True
                matched_suffix = suffix
                break

        if not has_facility_suffix:
            return False

        # 2. ì ‘ë‘ì‚¬ ë¶€ë¶„ ì¶”ì¶œ (ì‹œì„¤ëª… ì œì™¸)
        prefix = keyword_lower
        if matched_suffix:
            prefix = keyword_lower[:-len(matched_suffix)]

        # 3. ì§€ì—­ëª…ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ë¸Œëœë“œê°€ ì•„ë‹˜
        all_location_prefixes = (
            LOCAL_PATTERNS['prefixes'] +
            REGIONAL_PATTERNS['prefixes']
        )

        for loc_prefix in all_location_prefixes:
            if prefix.startswith(loc_prefix.lower()):
                return False

        # 4. íŠ¹ìˆ˜ ë¸Œëœë“œ íŒ¨í„´ ì²´í¬ (ì˜ë¬¸, ìˆ«ì í¬í•¨ ë“±)
        for pattern in self._brand_patterns:
            if pattern.match(keyword_lower):
                return True

        # 5. ì¼ë°˜ì ì¸ ë¸Œëœë“œ í‚¤ì›Œë“œ íŒë³„
        # ì ‘ë‘ì‚¬ê°€ 2ê¸€ì ì´ìƒì˜ í•œê¸€ì´ê³  ì§€ì—­ëª…ì´ ì•„ë‹ˆë©´ ë¸Œëœë“œë¡œ íŒì •
        # ì˜ˆ: "ë¡œë‹´í•œì˜ì›" â†’ "ë¡œë‹´" (2ê¸€ì, ì§€ì—­ëª… ì•„ë‹˜) â†’ ë¸Œëœë“œ
        if len(prefix) >= 2 and re.match(r'^[ê°€-í£]+$', prefix):
            # ì¶”ê°€ ê²€ì¦: ì¼ë°˜ ëª…ì‚¬ê°€ ì•„ë‹Œì§€ í™•ì¸
            common_prefixes = [
                'ì¢‹ì€', 'ë°”ë¥¸', 'ìƒˆë¡œìš´', 'í°', 'ì‘ì€', 'ì˜ˆìœ', 'ê±´ê°•í•œ',
                'í–‰ë³µí•œ', 'ë°ì€', 'íŠ¼íŠ¼', 'ì•„ë¦„ë‹¤ìš´', 'ì°¸', 'ì§„',
                'ë™ë„¤', 'ìš°ë¦¬', 'ê°€ì¡±', 'ì‚¬ë‘', 'ë¯¿ìŒ', 'ì •ì„±',
            ]
            # ì¼ë°˜ í˜•ìš©ì‚¬/ëª…ì‚¬ë¡œë§Œ ì‹œì‘í•˜ë©´ ë¸Œëœë“œë¡œ ì¶”ì •
            if any(prefix.startswith(cp) for cp in common_prefixes):
                return True
            # ê·¸ ì™¸ ì§€ì—­ëª…ì´ ì•„ë‹Œ 2-4ê¸€ì ì ‘ë‘ì‚¬ â†’ ë¸Œëœë“œ ê°€ëŠ¥ì„± ë†’ìŒ
            if 2 <= len(prefix) <= 6:
                return True

        return False

    def classify_search_intent(self, keyword: str, is_brand: bool, scope: KeywordScope) -> SearchIntent:
        """
        ê²€ìƒ‰ ì˜ë„ ë¶„ë¥˜

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            is_brand: ë¸Œëœë“œ í‚¤ì›Œë“œ ì—¬ë¶€
            scope: í‚¤ì›Œë“œ ë²”ìœ„

        Returns:
            SearchIntent: ê²€ìƒ‰ ì˜ë„
        """
        keyword_lower = keyword.lower().strip()

        # 1. ë¸Œëœë“œ í‚¤ì›Œë“œ â†’ ë„¤ë¹„ê²Œì´ì…˜
        if is_brand:
            return SearchIntent.NAVIGATIONAL

        # 2. ì§€ì—­ í‚¤ì›Œë“œ â†’ ì§€ì—­íƒìƒ‰
        if scope in [KeywordScope.LOCAL, KeywordScope.REGIONAL]:
            # ì˜ˆì•½/ê°€ê²© ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ê±°ë˜í˜•
            transaction_keywords = ['ì˜ˆì•½', 'ê°€ê²©', 'ë¹„ìš©', 'í• ì¸', 'ì´ë²¤íŠ¸', 'ìƒë‹´']
            if any(tk in keyword_lower for tk in transaction_keywords):
                return SearchIntent.TRANSACTIONAL
            return SearchIntent.LOCAL_SEARCH

        # 3. ê±°ë˜í˜• í‚¤ì›Œë“œ ì²´í¬
        transaction_keywords = ['ì˜ˆì•½', 'êµ¬ë§¤', 'ì‹ ì²­', 'ê°€ê²©', 'ë¹„ìš©', 'ê²¬ì ']
        if any(tk in keyword_lower for tk in transaction_keywords):
            return SearchIntent.TRANSACTIONAL

        # 4. ê¸°ë³¸: ì •ë³´í˜•
        return SearchIntent.INFORMATIONAL

    # ==============================================
    # ê³µì‹ ë¸”ë¡œê·¸ ê°ì§€
    # ==============================================

    def _detect_official_blog(
        self,
        keyword: str,
        blog_names: List[str]
    ) -> Tuple[bool, Optional[int]]:
        """
        ìƒìœ„ ë¸”ë¡œê·¸ ëª©ë¡ì—ì„œ ê³µì‹ ë¸”ë¡œê·¸ ê°ì§€

        ê³µì‹ ë¸”ë¡œê·¸ íŒë³„ ê¸°ì¤€:
        1. ë¸”ë¡œê·¸ ì´ë¦„ì— í‚¤ì›Œë“œ(ë³‘ì›ëª…)ê°€ í¬í•¨ëœ ê²½ìš°
        2. ë¸”ë¡œê·¸ ì´ë¦„ì´ "OOë³‘ì›", "OOì˜ì›", "OOí•œì˜ì›" ë“±ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
        3. ë¸”ë¡œê·¸ ì´ë¦„ì— "ê³µì‹", "official" ë“±ì´ í¬í•¨ëœ ê²½ìš°

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            blog_names: ìƒìœ„ ë¸”ë¡œê·¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ê³µì‹ ë¸”ë¡œê·¸ ì¡´ì¬ ì—¬ë¶€, ê³µì‹ ë¸”ë¡œê·¸ ìˆœìœ„)
        """
        if not blog_names:
            return False, None

        keyword_lower = keyword.lower().strip()

        # í‚¤ì›Œë“œì—ì„œ ì‹œì„¤ ì ‘ë¯¸ì‚¬ ì œê±°í•˜ì—¬ ë¸Œëœë“œëª… ì¶”ì¶œ
        brand_name = keyword_lower
        for suffix in BRAND_PATTERNS['facility_suffixes']:
            if keyword_lower.endswith(suffix):
                brand_name = keyword_lower[:-len(suffix)]
                break

        for idx, blog_name in enumerate(blog_names):
            if not blog_name:
                continue

            blog_name_lower = blog_name.lower().strip()

            # 1. í‚¤ì›Œë“œ(ë¸Œëœë“œëª…)ê°€ ë¸”ë¡œê·¸ ì´ë¦„ì— í¬í•¨
            if brand_name and len(brand_name) >= 2:
                if brand_name in blog_name_lower:
                    return True, idx + 1

            # 2. ì „ì²´ í‚¤ì›Œë“œê°€ ë¸”ë¡œê·¸ ì´ë¦„ì— í¬í•¨
            if keyword_lower in blog_name_lower:
                return True, idx + 1

            # 3. "ê³µì‹", "official" í¬í•¨
            if 'ê³µì‹' in blog_name_lower or 'official' in blog_name_lower:
                return True, idx + 1

            # 4. ë¸”ë¡œê·¸ ì´ë¦„ì´ ë³‘ì›/ì˜ì›ìœ¼ë¡œ ëë‚˜ë©´ì„œ í‚¤ì›Œë“œì™€ ìœ ì‚¬
            for suffix in ['ë³‘ì›', 'ì˜ì›', 'í•œì˜ì›', 'ì¹˜ê³¼', 'í´ë¦¬ë‹‰']:
                if blog_name_lower.endswith(suffix):
                    # ë¸”ë¡œê·¸ ì´ë¦„ì—ì„œ ë¸Œëœë“œ ë¶€ë¶„ ì¶”ì¶œ
                    blog_brand = blog_name_lower[:-len(suffix)]
                    # í‚¤ì›Œë“œ ë¸Œëœë“œì™€ ë¹„ìŠ·í•œì§€ í™•ì¸ (80% ì´ìƒ ì¼ì¹˜)
                    if blog_brand and brand_name:
                        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ì²´í¬
                        if blog_brand in brand_name or brand_name in blog_brand:
                            return True, idx + 1

        return False, None

    # ==============================================
    # í‚¤ì›Œë“œ ë²”ìœ„ ë¶„ë¥˜
    # ==============================================

    def classify_scope(self, keyword: str) -> KeywordScope:
        """
        í‚¤ì›Œë“œê°€ ë¸Œëœë“œ/ì§€ì—­/ê´‘ì—­/ì „êµ­ì¸ì§€ ë¶„ë¥˜

        ë¸Œëœë“œ í‚¤ì›Œë“œ: íŠ¹ì • ë³‘ì›/ë¸Œëœë“œëª… (ì˜ˆ: ë¡œë‹´í•œì˜ì›) - ê³µì‹ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •
        ì§€ì—­ í‚¤ì›Œë“œ: íŠ¹ì • ì§€ì—­ + ì‹œì„¤/ì„œë¹„ìŠ¤ (ì˜ˆ: ê°•ë‚¨ì—­ í•œì˜ì›, í™ëŒ€ì—¬ë“œë¦„)
        ê´‘ì—­ í‚¤ì›Œë“œ: ì‹œ/ë„ ë‹¨ìœ„ (ì˜ˆ: ì„œìš¸ í•œì˜ì›)
        ì „êµ­ í‚¤ì›Œë“œ: ì§€ì—­ ì—†ëŠ” ì¼ë°˜ (ì˜ˆ: í—ˆë¦¬ë””ìŠ¤í¬ ì¹˜ë£Œ)
        """
        keyword_lower = keyword.lower().strip()

        # 0. ë¸Œëœë“œ í‚¤ì›Œë“œ ì²´í¬ (ê°€ì¥ ë¨¼ì €!) - ë¡œë‹´í•œì˜ì› ë“±
        if self.is_brand_keyword(keyword):
            return KeywordScope.BRAND

        # 1. ì§€ì—­ í‚¤ì›Œë“œ íŒ¨í„´ ì²´í¬ (ì •ê·œì‹)
        for pattern in self._local_patterns:
            if pattern.search(keyword_lower):
                return KeywordScope.LOCAL

        # 2. ì ‘ë‘ì‚¬ + ì‹œì„¤/ì„œë¹„ìŠ¤ ì²´í¬ (í™•ì¥ëœ ë¡œì§)
        for prefix in LOCAL_PATTERNS['prefixes']:
            if keyword_lower.startswith(prefix):
                # 2-1. ë³‘ì›/ì˜ì› ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
                if any(h in keyword_lower for h in ['ë³‘ì›', 'ì˜ì›', 'í•œì˜ì›', 'ì¹˜ê³¼', 'í´ë¦¬ë‹‰', 'ì„¼í„°']):
                    return KeywordScope.LOCAL

                # 2-2. ì˜ë£Œ/ë¯¸ìš© ì„œë¹„ìŠ¤ í‚¤ì›Œë“œ ì²´í¬ (ìƒˆë¡œ ì¶”ê°€)
                # "í™ëŒ€ì—¬ë“œë¦„", "ì‹ ì´Œì—¬ë“œë¦„í‰í„°", "ìœ„ë¡€ë‹¤ì´ì–´íŠ¸í•œì•½" ë“± ì¸ì‹
                if any(service in keyword_lower for service in LOCAL_PATTERNS.get('medical_services', [])):
                    return KeywordScope.LOCAL

        # 3. ê´‘ì—­ í‚¤ì›Œë“œ ì²´í¬
        for prefix in REGIONAL_PATTERNS['prefixes']:
            if keyword_lower.startswith(prefix):
                # ê´‘ì—­ë„ ì„œë¹„ìŠ¤ í‚¤ì›Œë“œì™€ ê²°í•© ì‹œ ê´‘ì—­ìœ¼ë¡œ ë¶„ë¥˜
                if any(h in keyword_lower for h in ['ë³‘ì›', 'ì˜ì›', 'í•œì˜ì›', 'ì¹˜ê³¼', 'í´ë¦¬ë‹‰', 'ì„¼í„°']):
                    return KeywordScope.REGIONAL
                if any(service in keyword_lower for service in LOCAL_PATTERNS.get('medical_services', [])):
                    return KeywordScope.REGIONAL

        # 4. ê¸°ë³¸: ì „êµ­ í‚¤ì›Œë“œ
        return KeywordScope.NATIONAL

    # ==============================================
    # ì•ˆì „ ë§ˆì§„ ê³„ì‚°
    # ==============================================

    def calculate_safety_margin(
        self,
        scope: KeywordScope,
        top10_std: float,
        influencer_count: int,
        has_official_blog: bool = False
    ) -> int:
        """
        ì•ˆì „ ë§ˆì§„ ê³„ì‚° (5ìœ„ ë³´ì¥ ì‹œìŠ¤í…œìš© ê°•í™” ë²„ì „)

        ì „êµ­ í‚¤ì›Œë“œì¼ìˆ˜ë¡, ê²½ìŸ ë³€ë™ì„±ì´ í´ìˆ˜ë¡ ë§ˆì§„ ì¦ê°€

        í”¼ë“œë°± ë°˜ì˜:
        - ì „êµ­ í‚¤ì›Œë“œ 7ìœ„ ì˜ˆì¸¡ â†’ ì‹¤ì œ 10ìœ„ê¶Œ ë°– (ì˜¤ì°¨ +3~4)
        - 5ìœ„ ë³´ì¥ì„ ìœ„í•´ ë” ë³´ìˆ˜ì ì¸ ë§ˆì§„ ì ìš©
        - ë¸Œëœë“œ í‚¤ì›Œë“œëŠ” ë§¤ìš° ë†’ì€ ë§ˆì§„ ì ìš© (ì‚¬ì‹¤ìƒ ì§„ì… ë¶ˆê°€)
        """
        margin = 0

        # 0. ë¸Œëœë“œ í‚¤ì›Œë“œëŠ” ë§¤ìš° ë†’ì€ ë§ˆì§„ (ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •)
        if scope == KeywordScope.BRAND:
            margin = 10  # ì‚¬ì‹¤ìƒ ìƒìœ„ë…¸ì¶œ ë¶ˆê°€ëŠ¥
            return margin

        # 1. í‚¤ì›Œë“œ ë²”ìœ„ë³„ ê¸°ë³¸ ë§ˆì§„ (ê°•í™”ë¨)
        if scope == KeywordScope.LOCAL:
            margin = 1  # ì§€ì—­ë„ ì•½ê°„ì˜ ì˜¤ì°¨ ì¡´ì¬
        elif scope == KeywordScope.REGIONAL:
            margin = 2  # ê´‘ì—­ì€ +2
        else:  # NATIONAL
            margin = 3  # ì „êµ­ì€ ê¸°ë³¸ +3 (7ìœ„â†’10ìœ„ ì˜¤ì°¨ ë°˜ì˜)

        # 2. ê²½ìŸ ë³€ë™ì„±ì— ë”°ë¥¸ ì¶”ê°€ ë§ˆì§„ (ê°•í™”ë¨)
        # í‘œì¤€í¸ì°¨ê°€ í¬ë©´ ìˆœìœ„ ë³€ë™ì´ ì‹¬í•¨
        if top10_std > 15:
            margin += 3
        elif top10_std > 10:
            margin += 2
        elif top10_std > 5:
            margin += 1

        # 3. ì¸í”Œë£¨ì–¸ì„œ ìˆ˜ì— ë”°ë¥¸ ì¶”ê°€ ë§ˆì§„ (ê°•í™”ë¨)
        if influencer_count >= 3:
            margin += 3
        elif influencer_count >= 2:
            margin += 2
        elif influencer_count >= 1:
            margin += 1

        # 4. ê³µì‹ ë¸”ë¡œê·¸ ì¡´ì¬ ì‹œ ì¶”ê°€ ë§ˆì§„
        if has_official_blog:
            margin += 2

        return min(margin, 10)  # ìµœëŒ€ 10ê¹Œì§€

    # ==============================================
    # ì˜ˆì¸¡ ìˆœìœ„ ê³„ì‚°
    # ==============================================

    def calculate_predicted_rank(
        self,
        my_score: float,
        top10_scores: List[float]
    ) -> int:
        """
        ë‚´ ì ìˆ˜ ê¸°ì¤€ ì˜ˆìƒ ìˆœìœ„ ê³„ì‚°

        ìƒìœ„ ë¸”ë¡œê·¸ ì ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ë‚´ ì˜ˆìƒ ìˆœìœ„ ì‚°ì¶œ
        """
        if not top10_scores:
            return 10

        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_scores = sorted(top10_scores, reverse=True)

        predicted_rank = 1
        for score in sorted_scores:
            if my_score < score:
                predicted_rank += 1
            else:
                break

        return min(predicted_rank, len(sorted_scores) + 1)

    # ==============================================
    # ì•ˆì „ ì§€ìˆ˜ ê³„ì‚°
    # ==============================================

    def calculate_safety_score(
        self,
        my_score: float,
        top10_scores: List[float],
        scope: KeywordScope,
        adjusted_rank: int,
        influencer_count: int
    ) -> Tuple[float, Dict]:
        """
        ì•ˆì „ ì§€ìˆ˜ ê³„ì‚° (0-100)

        Safety Score =
            (ì ìˆ˜ì—¬ìœ ë„ Ã— 0.30) +
            (ìˆœìœ„ì•ˆì •ì„± Ã— 0.25) +
            (ê²½ìŸì•½ë„ Ã— 0.25) +
            (ì˜ˆì¸¡ì‹ ë¢°ë„ Ã— 0.20)
        """
        if not top10_scores:
            return 0.0, {}

        top10_avg = np.mean(top10_scores)
        top10_min = min(top10_scores)
        top10_std = np.std(top10_scores)

        # 1. ì ìˆ˜ ì—¬ìœ ë„ (30%) - ë‚´ ì ìˆ˜ê°€ ìµœì € ì ìˆ˜ë³´ë‹¤ ì–¼ë§ˆë‚˜ ë†’ì€ê°€
        score_gap = my_score - top10_min
        if score_gap >= 20:
            score_buffer_score = 100
        elif score_gap >= 10:
            score_buffer_score = 80 + (score_gap - 10) * 2
        elif score_gap >= 0:
            score_buffer_score = 60 + score_gap * 2
        elif score_gap >= -10:
            score_buffer_score = 40 + (score_gap + 10) * 2
        elif score_gap >= -20:
            score_buffer_score = 20 + (score_gap + 20) * 1
        else:
            score_buffer_score = max(0, 10 + score_gap)

        # 2. ìˆœìœ„ ì•ˆì •ì„± (25%) - í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì 
        if top10_std <= 5:
            stability_score = 100
        elif top10_std <= 10:
            stability_score = 80 - (top10_std - 5) * 4
        elif top10_std <= 15:
            stability_score = 60 - (top10_std - 10) * 4
        else:
            stability_score = max(20, 40 - (top10_std - 15) * 2)

        # 3. ê²½ìŸ ì•½ë„ (25%) - ìƒìœ„ í‰ê·  ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡, ì¸í”Œë£¨ì–¸ì„œê°€ ì ì„ìˆ˜ë¡
        competition_score = 100

        # ìƒìœ„ í‰ê·  ì ìˆ˜ ê¸°ë°˜
        if top10_avg >= 70:
            competition_score -= 40
        elif top10_avg >= 60:
            competition_score -= 25
        elif top10_avg >= 50:
            competition_score -= 10

        # ì¸í”Œë£¨ì–¸ì„œ íŒ¨ë„í‹°
        competition_score -= influencer_count * 15
        competition_score = max(0, competition_score)

        # 4. ì˜ˆì¸¡ ì‹ ë¢°ë„ (20%) - í‚¤ì›Œë“œ ë²”ìœ„ì™€ ì˜ˆì¸¡ ìˆœìœ„ ê¸°ë°˜
        confidence_matrix = {
            KeywordScope.LOCAL: {
                1: 95, 2: 90, 3: 85, 4: 75, 5: 65, 6: 55, 7: 40, 8: 30
            },
            KeywordScope.REGIONAL: {
                1: 85, 2: 80, 3: 70, 4: 60, 5: 50, 6: 40, 7: 25, 8: 15
            },
            KeywordScope.NATIONAL: {
                1: 80, 2: 70, 3: 60, 4: 45, 5: 35, 6: 25, 7: 15, 8: 10
            },
            # ë¸Œëœë“œ í‚¤ì›Œë“œëŠ” ì‹ ë¢°ë„ ë§¤ìš° ë‚®ìŒ (ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •)
            KeywordScope.BRAND: {
                1: 20, 2: 15, 3: 10, 4: 5, 5: 5, 6: 5, 7: 5, 8: 5
            }
        }

        confidence_score = confidence_matrix.get(scope, {}).get(
            min(adjusted_rank, 8), 10
        )

        # ì¢…í•© ì ìˆ˜
        safety_score = (
            score_buffer_score * 0.30 +
            stability_score * 0.25 +
            competition_score * 0.25 +
            confidence_score * 0.20
        )

        breakdown = {
            'score_buffer': round(score_buffer_score, 1),
            'stability': round(stability_score, 1),
            'competition': round(competition_score, 1),
            'confidence': round(confidence_score, 1)
        }

        return round(safety_score, 1), breakdown

    def get_safety_grade(self, safety_score: float) -> SafetyGrade:
        """ì•ˆì „ ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ë°˜í™˜"""
        if safety_score >= 80:
            return SafetyGrade.VERY_SAFE
        elif safety_score >= 65:
            return SafetyGrade.SAFE
        elif safety_score >= 50:
            return SafetyGrade.MODERATE
        elif safety_score >= 35:
            return SafetyGrade.RISKY
        else:
            return SafetyGrade.VERY_RISKY

    # ==============================================
    # ì¶”ì²œ ìœ í˜• ê²°ì •
    # ==============================================

    def determine_recommendation(
        self,
        safety_grade: SafetyGrade,
        adjusted_rank: int,
        scope: KeywordScope,
        score_gap: float,
        is_brand: bool = False,
        has_official_blog: bool = False
    ) -> Tuple[RecommendationType, List[str]]:
        """
        ì¶”ì²œ ìœ í˜• ë° ì´ìœ  ê²°ì •

        í•µì‹¬ ê·œì¹™:
        - ë¸Œëœë“œ í‚¤ì›Œë“œ â†’ ë¬´ì¡°ê±´ íšŒí”¼ (ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •)
        - ì „êµ­ í‚¤ì›Œë“œ 7ìœ„ ì´í•˜ â†’ ë¹„ì¶”ì²œ/íšŒí”¼
        - ì§€ì—­ í‚¤ì›Œë“œëŠ” 8ìœ„ê¹Œì§€ í—ˆìš©
        - ì ìˆ˜ ì—¬ìœ ê°€ ì¶©ë¶„í•´ì•¼ ì•ˆì „
        """
        reasons = []

        # 0. ë¸Œëœë“œ í‚¤ì›Œë“œ â†’ ë¬´ì¡°ê±´ íšŒí”¼
        if scope == KeywordScope.BRAND or is_brand:
            reasons.append("ğŸ¢ ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ - ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ ê³ ì •")
            reasons.append("ì¼ë°˜ ë¸”ë¡œê±°ê°€ ìƒìœ„ë…¸ì¶œí•˜ê¸° ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤")
            return RecommendationType.AVOID, reasons

        # 0-1. ê³µì‹ ë¸”ë¡œê·¸ ì¡´ì¬ ì‹œ ê²½ê³ 
        if has_official_blog:
            reasons.append("âš ï¸ í•´ë‹¹ í‚¤ì›Œë“œì— ê³µì‹ ë¸”ë¡œê·¸ê°€ ìƒìœ„ì— ìˆìŠµë‹ˆë‹¤")

        # 1. ì¡°ì •ëœ ìˆœìœ„ ê¸°ë°˜ 1ì°¨ í•„í„°
        if scope == KeywordScope.NATIONAL:
            # ì „êµ­ í‚¤ì›Œë“œ: 6ìœ„ ì´ë‚´ë§Œ ì¶”ì²œ
            if adjusted_rank > 8:
                reasons.append(f"ì „êµ­ í‚¤ì›Œë“œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ìƒìœ„ë…¸ì¶œ ë¶ˆê°€ëŠ¥")
                return RecommendationType.AVOID, reasons
            elif adjusted_rank > 6:
                reasons.append(f"ì „êµ­ í‚¤ì›Œë“œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ì§„ì… ì–´ë ¤ì›€")
                return RecommendationType.NOT_RECOMMEND, reasons

        elif scope == KeywordScope.REGIONAL:
            # ê´‘ì—­ í‚¤ì›Œë“œ: 7ìœ„ ì´ë‚´ë§Œ ì¶”ì²œ
            if adjusted_rank > 9:
                reasons.append(f"ê´‘ì—­ í‚¤ì›Œë“œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ìƒìœ„ë…¸ì¶œ ë¶ˆê°€ëŠ¥")
                return RecommendationType.AVOID, reasons
            elif adjusted_rank > 7:
                reasons.append(f"ê´‘ì—­ í‚¤ì›Œë“œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ì§„ì… ì–´ë ¤ì›€")
                return RecommendationType.NOT_RECOMMEND, reasons

        elif scope == KeywordScope.LOCAL:
            # ì§€ì—­ í‚¤ì›Œë“œ: 8ìœ„ ì´ë‚´ ì¶”ì²œ
            if adjusted_rank > 10:
                reasons.append(f"ì§€ì—­ í‚¤ì›Œë“œì§€ë§Œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ê²½ìŸ ì¹˜ì—´")
                return RecommendationType.AVOID, reasons
            elif adjusted_rank > 8:
                reasons.append(f"ì§€ì—­ í‚¤ì›Œë“œ {adjusted_rank}ìœ„ ì˜ˆì¸¡ - ì•½ê°„ ì–´ë ¤ì›€")
                return RecommendationType.CONDITIONAL, reasons

        # 2. ì•ˆì „ ë“±ê¸‰ ê¸°ë°˜ 2ì°¨ ê²°ì •
        if safety_grade == SafetyGrade.VERY_SAFE:
            reasons.append("ë†’ì€ ì•ˆì „ ì§€ìˆ˜ - ìƒìœ„ë…¸ì¶œ ê°€ëŠ¥ì„± ë§¤ìš° ë†’ìŒ")
            if score_gap >= 10:
                reasons.append(f"ì ìˆ˜ ì—¬ìœ  +{score_gap:.0f}ì ")
            return RecommendationType.STRONGLY_RECOMMEND, reasons

        elif safety_grade == SafetyGrade.SAFE:
            reasons.append("ì•ˆì „ ì§€ìˆ˜ ì–‘í˜¸ - ìƒìœ„ë…¸ì¶œ ê¸°ëŒ€ë¨")
            return RecommendationType.RECOMMEND, reasons

        elif safety_grade == SafetyGrade.MODERATE:
            reasons.append("ë³´í†µ ìˆ˜ì¤€ - ì½˜í…ì¸  í’ˆì§ˆì— ë”°ë¼ ê°€ëŠ¥")
            return RecommendationType.CONDITIONAL, reasons

        elif safety_grade == SafetyGrade.RISKY:
            reasons.append("ìœ„í—˜ ìˆ˜ì¤€ - ìƒìœ„ë…¸ì¶œ ë¶ˆí™•ì‹¤")
            return RecommendationType.NOT_RECOMMEND, reasons

        else:
            reasons.append("ë§¤ìš° ìœ„í—˜ - ì‹œê°„ ë‚­ë¹„ ê°€ëŠ¥ì„±")
            return RecommendationType.AVOID, reasons

    # ==============================================
    # íŒ ë° ê²½ê³  ìƒì„±
    # ==============================================

    def generate_tips(
        self,
        recommendation: RecommendationType,
        scope: KeywordScope,
        adjusted_rank: int,
        score_gap: float,
        top10_avg: float
    ) -> List[str]:
        """ìƒí™©ë³„ íŒ ìƒì„±"""
        tips = []

        if recommendation in [RecommendationType.STRONGLY_RECOMMEND, RecommendationType.RECOMMEND]:
            tips.append("âœ… ì´ í‚¤ì›Œë“œë¡œ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”")
            if scope == KeywordScope.LOCAL:
                tips.append("ğŸ“ ì§€ì—­ ì •ë³´ë¥¼ ìƒì„¸íˆ í¬í•¨í•˜ë©´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤")
            if score_gap >= 15:
                tips.append("ğŸ’ª ì ìˆ˜ ì—¬ìœ ê°€ ì¶©ë¶„í•´ ì•ˆì •ì ì¸ ìƒìœ„ë…¸ì¶œì´ ê¸°ëŒ€ë©ë‹ˆë‹¤")

        elif recommendation == RecommendationType.CONDITIONAL:
            tips.append("âš ï¸ ì½˜í…ì¸  í’ˆì§ˆì„ ë†’ì—¬ì•¼ ìƒìœ„ë…¸ì¶œ ê°€ëŠ¥")
            tips.append("ğŸ“ ìƒìœ„ ë¸”ë¡œê·¸ë³´ë‹¤ ë” ê¸´ ê¸€, ë” ë§ì€ ì´ë¯¸ì§€ í•„ìš”")
            if score_gap < 0:
                tips.append(f"ğŸ“ˆ ë¸”ë¡œê·¸ ì§€ìˆ˜ë¥¼ {abs(score_gap):.0f}ì  ì˜¬ë¦¬ë©´ ìœ ë¦¬í•´ì§‘ë‹ˆë‹¤")

        elif recommendation == RecommendationType.NOT_RECOMMEND:
            tips.append("âŒ ì´ í‚¤ì›Œë“œëŠ” ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            tips.append("ğŸ” ë” ì„¸ë¶€ì ì¸ í‚¤ì›Œë“œë‚˜ ì§€ì—­ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ë³´ì„¸ìš”")
            if scope == KeywordScope.NATIONAL:
                tips.append("ğŸ’¡ ì „êµ­ í‚¤ì›Œë“œë³´ë‹¤ ì§€ì—­ í‚¤ì›Œë“œê°€ ì§„ì…í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤")

        else:  # AVOID
            tips.append("ğŸš« ì´ í‚¤ì›Œë“œëŠ” í”¼í•˜ì„¸ìš”")
            tips.append("â° ì‹œê°„ ë‚­ë¹„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤")

        return tips

    def generate_warnings(
        self,
        scope: KeywordScope,
        raw_rank: int,
        adjusted_rank: int,
        influencer_count: int,
        top10_std: float
    ) -> List[str]:
        """ê²½ê³  ë©”ì‹œì§€ ìƒì„±"""
        warnings = []

        # ì•ˆì „ ë§ˆì§„ ì ìš© ê²½ê³ 
        if adjusted_rank > raw_rank:
            margin = adjusted_rank - raw_rank
            warnings.append(
                f"âš ï¸ ì•ˆì „ë§ˆì§„ +{margin} ì ìš©ë¨ (ì›ë˜ ì˜ˆì¸¡: {raw_rank}ìœ„ â†’ ë³´ì •: {adjusted_rank}ìœ„)"
            )

        # ì „êµ­ í‚¤ì›Œë“œ 7ìœ„ ì´í•˜ ê²½ê³ 
        if scope == KeywordScope.NATIONAL and adjusted_rank >= 7:
            warnings.append(
                "ğŸš¨ ì „êµ­ í‚¤ì›Œë“œ 7ìœ„ ì´í•˜ëŠ” ì‹¤ì œ ìƒìœ„ë…¸ì¶œì´ ì–´ë µìŠµë‹ˆë‹¤ (í”¼ë“œë°± ê¸°ë°˜)"
            )

        # ì¸í”Œë£¨ì–¸ì„œ ê²½ê³ 
        if influencer_count >= 3:
            warnings.append(
                f"ğŸ‘‘ ì¸í”Œë£¨ì–¸ì„œ {influencer_count}ëª… - ê²½ìŸì´ ë§¤ìš° ì¹˜ì—´í•©ë‹ˆë‹¤"
            )
        elif influencer_count >= 1:
            warnings.append(
                f"ğŸ‘‘ ì¸í”Œë£¨ì–¸ì„œ {influencer_count}ëª… - ìˆœìœ„ ë³€ë™ ê°€ëŠ¥ì„±"
            )

        # ë³€ë™ì„± ê²½ê³ 
        if top10_std > 15:
            warnings.append(
                "ğŸ“Š ìˆœìœ„ ë³€ë™ì´ ì‹¬í•œ í‚¤ì›Œë“œì…ë‹ˆë‹¤ - ì˜ˆì¸¡ ë¶ˆí™•ì‹¤"
            )

        return warnings

    # ==============================================
    # ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
    # ==============================================

    def analyze_keyword_safety(
        self,
        keyword: str,
        my_score: float,
        top10_scores: List[float],
        search_volume: int = 0,
        influencer_count: int = 0,
        top10_blog_names: List[str] = None,
        has_official_blog: bool = False,
        official_blog_rank: int = None,
        posts_data: List[Dict] = None
    ) -> SafetyAnalysis:
        """
        í‚¤ì›Œë“œ ì•ˆì „ì„± ì¢…í•© ë¶„ì„

        Args:
            keyword: ë¶„ì„í•  í‚¤ì›Œë“œ
            my_score: ë‚´ ë¸”ë¡œê·¸ ì ìˆ˜
            top10_scores: ìƒìœ„ 10ê°œ ë¸”ë¡œê·¸ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
            search_volume: ì›”ê°„ ê²€ìƒ‰ëŸ‰
            influencer_count: ìƒìœ„ 10ê°œ ì¤‘ ì¸í”Œë£¨ì–¸ì„œ ìˆ˜
            top10_blog_names: ìƒìœ„ 10ê°œ ë¸”ë¡œê·¸ ì´ë¦„ (ê³µì‹ ë¸”ë¡œê·¸ ê°ì§€ìš©)
            has_official_blog: ê³µì‹ ë¸”ë¡œê·¸ ì¡´ì¬ ì—¬ë¶€ (ì™¸ë¶€ì—ì„œ ì „ë‹¬)
            official_blog_rank: ê³µì‹ ë¸”ë¡œê·¸ ìˆœìœ„ (ì™¸ë¶€ì—ì„œ ì „ë‹¬)
            posts_data: ìƒìœ„ í¬ìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„° (ê²½ìŸë„ ì •ë°€ ë¶„ì„ìš©)

        Returns:
            SafetyAnalysis: ì¢…í•© ì•ˆì „ì„± ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ í†µê³„
        if not top10_scores:
            top10_scores = [50] * 10  # ê¸°ë³¸ê°’

        top10_avg = float(np.mean(top10_scores))
        top10_min = float(min(top10_scores))
        top10_std = float(np.std(top10_scores))
        score_gap = my_score - top10_min
        score_buffer = (score_gap / top10_min * 100) if top10_min > 0 else 0

        # 0. ë¸Œëœë“œ í‚¤ì›Œë“œ ì²´í¬ (ì‹ ê·œ)
        is_brand = self.is_brand_keyword(keyword)

        # 1. í‚¤ì›Œë“œ ë²”ìœ„ ë¶„ë¥˜ (ë¸Œëœë“œ í¬í•¨)
        scope = self.classify_scope(keyword)

        # 1-1. ê²€ìƒ‰ ì˜ë„ ë¶„ë¥˜ (ì‹ ê·œ)
        search_intent = self.classify_search_intent(keyword, is_brand, scope)

        # 1-2. ê³µì‹ ë¸”ë¡œê·¸ ê°ì§€ (ë¸”ë¡œê·¸ ì´ë¦„ ê¸°ë°˜)
        if not has_official_blog and top10_blog_names:
            detected_official, detected_rank = self._detect_official_blog(
                keyword, top10_blog_names
            )
            if detected_official:
                has_official_blog = True
                official_blog_rank = detected_rank

        # 2. ì›ë³¸ ì˜ˆì¸¡ ìˆœìœ„
        raw_predicted_rank = self.calculate_predicted_rank(my_score, top10_scores)

        # 3. ì•ˆì „ ë§ˆì§„ ê³„ì‚° (ë¸Œëœë“œ/ê³µì‹ ë¸”ë¡œê·¸ ë°˜ì˜)
        safety_margin = self.calculate_safety_margin(
            scope, top10_std, influencer_count, has_official_blog
        )

        # 4. ë³´ì •ëœ ìˆœìœ„
        adjusted_rank = raw_predicted_rank + safety_margin

        # 5. ì•ˆì „ ì§€ìˆ˜ ê³„ì‚°
        safety_score, breakdown = self.calculate_safety_score(
            my_score, top10_scores, scope, adjusted_rank, influencer_count
        )

        # ë¸Œëœë“œ í‚¤ì›Œë“œëŠ” ì•ˆì „ ì§€ìˆ˜ ëŒ€í­ ê°ì†Œ
        if is_brand or scope == KeywordScope.BRAND:
            safety_score = min(safety_score, 15)  # ìµœëŒ€ 15ì 

        # 6. ì•ˆì „ ë“±ê¸‰
        safety_grade = self.get_safety_grade(safety_score)

        # 7. ì˜ˆì¸¡ ì‹ ë¢°ë„
        confidence = breakdown.get('confidence', 50)

        # 8. ì¶”ì²œ ìœ í˜• ê²°ì • (ë¸Œëœë“œ/ê³µì‹ ë¸”ë¡œê·¸ ë°˜ì˜)
        recommendation, reasons = self.determine_recommendation(
            safety_grade, adjusted_rank, scope, score_gap,
            is_brand=is_brand, has_official_blog=has_official_blog
        )

        # 9. íŒ ìƒì„±
        tips = self.generate_tips(
            recommendation, scope, adjusted_rank, score_gap, top10_avg
        )

        # ë¸Œëœë“œ í‚¤ì›Œë“œ ì „ìš© íŒ ì¶”ê°€
        if is_brand or scope == KeywordScope.BRAND:
            tips = [
                "ğŸš« ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œëŠ” ìƒìœ„ë…¸ì¶œì´ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤",
                "ğŸ’¡ í•´ë‹¹ ë³‘ì›ì˜ ê³µì‹ ë¸”ë¡œê·¸ê°€ í•­ìƒ ìƒìœ„ì— ë…¸ì¶œë©ë‹ˆë‹¤",
                "ğŸ” ì§€ì—­+ì„œë¹„ìŠ¤ í‚¤ì›Œë“œë¡œ ëŒ€ì²´í•˜ì„¸ìš” (ì˜ˆ: ê°•ë‚¨ ì—¬ë“œë¦„ ì¹˜ë£Œ)",
            ] + tips

        # 10. ê²½ê³  ìƒì„±
        warnings = self.generate_warnings(
            scope, raw_predicted_rank, adjusted_rank, influencer_count, top10_std
        )

        # ë¸Œëœë“œ í‚¤ì›Œë“œ ê²½ê³  ì¶”ê°€
        if is_brand or scope == KeywordScope.BRAND:
            warnings.insert(0, "ğŸ¢ ë¸Œëœë“œ/ë³‘ì›ëª… í‚¤ì›Œë“œ ê°ì§€ - ìƒìœ„ë…¸ì¶œ ë¶ˆê°€ëŠ¥")

        # ê³ ì ì ìˆ˜ ê³„ì‚°
        high_scorer_count = sum(1 for s in top10_scores if s >= 70)

        # 11. ì •ë°€ ê²½ìŸë„ ë¶„ì„ (posts_dataê°€ ìˆì„ ë•Œë§Œ)
        comp_analysis = None
        content_relevance_score = 0.0
        freshness_score = 0.0
        engagement_score = 0.0
        total_competition_score = 0.0
        competition_difficulty = "ë³´í†µ"

        if posts_data:
            try:
                comp_analysis = competition_analyzer.analyze(
                    keyword=keyword,
                    blog_scores=top10_scores,
                    posts_data=posts_data,
                    my_score=my_score
                )

                content_relevance_score = comp_analysis.content_relevance.score
                freshness_score = comp_analysis.freshness.score
                engagement_score = comp_analysis.engagement.score
                total_competition_score = comp_analysis.total_competition_score
                competition_difficulty = comp_analysis.difficulty.value

                # ê²½ìŸë„ ë¶„ì„ ê¸°ë°˜ ì¶”ê°€ ê²½ê³ /íŒ
                warnings.extend(comp_analysis.warnings)
                tips.extend(comp_analysis.recommendations)

                # ê²½ìŸë„ê°€ ë†’ìœ¼ë©´ ì•ˆì „ ì ìˆ˜ ì¶”ê°€ ê°ì†Œ
                if total_competition_score >= 70:
                    safety_score = max(0, safety_score - 15)
                    safety_grade = self.get_safety_grade(safety_score)
                elif total_competition_score >= 55:
                    safety_score = max(0, safety_score - 8)
                    safety_grade = self.get_safety_grade(safety_score)

            except Exception as e:
                logger.warning(f"Competition analysis failed for {keyword}: {e}")

        # 11. 5ìœ„ ë³´ì¥ ì—¬ë¶€ íŒì •
        is_guaranteed_top5, guaranteed_top5_reasons = self.check_guaranteed_top5(
            scope=scope,
            raw_predicted_rank=raw_predicted_rank,
            adjusted_rank=adjusted_rank,
            safety_score=safety_score,
            score_gap=score_gap,
            top10_std=top10_std,
            influencer_count=influencer_count,
            high_scorer_count=high_scorer_count
        )

        return SafetyAnalysis(
            keyword=keyword,
            scope=scope,
            raw_predicted_rank=raw_predicted_rank,
            safety_margin=safety_margin,
            adjusted_rank=adjusted_rank,
            my_score=my_score,
            top10_scores=top10_scores,
            top10_avg=round(top10_avg, 1),
            top10_min=round(top10_min, 1),
            top10_std=round(top10_std, 1),
            score_gap=round(score_gap, 1),
            score_buffer=round(score_buffer, 1),
            influencer_count=influencer_count,
            high_scorer_count=high_scorer_count,
            safety_score=safety_score,
            safety_grade=safety_grade,
            confidence=confidence,
            recommendation=recommendation,
            reasons=reasons,
            tips=tips,
            search_volume=search_volume,
            warnings=warnings,
            is_guaranteed_top5=is_guaranteed_top5,
            guaranteed_top5_reasons=guaranteed_top5_reasons,
            # ê²€ìƒ‰ ì˜ë„ ë¶„ì„
            search_intent=search_intent,
            is_brand_keyword=is_brand,
            has_official_blog=has_official_blog,
            official_blog_rank=official_blog_rank,
            # ì •ë°€ ê²½ìŸë„ ë¶„ì„
            competition_analysis=comp_analysis,
            content_relevance_score=content_relevance_score,
            freshness_score=freshness_score,
            engagement_score=engagement_score,
            total_competition_score=total_competition_score,
            competition_difficulty=competition_difficulty
        )

    # ==============================================
    # í‚¤ì›Œë“œ í•„í„°ë§ (ì•ˆì „í•œ ê²ƒë§Œ)
    # ==============================================

    def filter_safe_keywords(
        self,
        keywords_data: List[Dict],
        my_score: float,
        min_safety_score: float = 50.0,
        min_search_volume: int = 100
    ) -> List[SafetyAnalysis]:
        """
        ì•ˆì „í•œ í‚¤ì›Œë“œë§Œ í•„í„°ë§

        Args:
            keywords_data: í‚¤ì›Œë“œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
                          [{'keyword': str, 'top10_scores': list, 'search_volume': int, ...}, ...]
            my_score: ë‚´ ë¸”ë¡œê·¸ ì ìˆ˜
            min_safety_score: ìµœì†Œ ì•ˆì „ ì ìˆ˜ (ê¸°ë³¸ 50)
            min_search_volume: ìµœì†Œ ê²€ìƒ‰ëŸ‰ (ê¸°ë³¸ 100)

        Returns:
            ì•ˆì „ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ëœ SafetyAnalysis ë¦¬ìŠ¤íŠ¸
        """
        safe_keywords = []

        for kw_data in keywords_data:
            keyword = kw_data.get('keyword', '')
            top10_scores = kw_data.get('top10_scores', [])
            search_volume = kw_data.get('search_volume', 0)
            influencer_count = kw_data.get('influencer_count', 0)

            # ê²€ìƒ‰ëŸ‰ í•„í„°
            if search_volume < min_search_volume:
                continue

            # ì•ˆì „ì„± ë¶„ì„
            analysis = self.analyze_keyword_safety(
                keyword=keyword,
                my_score=my_score,
                top10_scores=top10_scores,
                search_volume=search_volume,
                influencer_count=influencer_count
            )

            # ì•ˆì „ ì ìˆ˜ í•„í„°
            if analysis.safety_score >= min_safety_score:
                safe_keywords.append(analysis)

        # ì•ˆì „ ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        safe_keywords.sort(key=lambda x: x.safety_score, reverse=True)

        return safe_keywords

    def get_top_safe_keywords(
        self,
        keywords_data: List[Dict],
        my_score: float,
        top_n: int = 10
    ) -> List[SafetyAnalysis]:
        """
        ê°€ì¥ ì•ˆì „í•œ ìƒìœ„ Nê°œ í‚¤ì›Œë“œ ë°˜í™˜

        ì¶”ì²œ ê¸°ì¤€:
        1. ê°•ë ¥ì¶”ì²œ/ì¶”ì²œ ìœ í˜•ë§Œ
        2. ì•ˆì „ ì ìˆ˜ 65 ì´ìƒ
        3. ê²€ìƒ‰ëŸ‰ 100 ì´ìƒ
        """
        all_safe = self.filter_safe_keywords(
            keywords_data=keywords_data,
            my_score=my_score,
            min_safety_score=65.0,
            min_search_volume=100
        )

        # ê°•ë ¥ì¶”ì²œ/ì¶”ì²œë§Œ í•„í„°
        recommended = [
            kw for kw in all_safe
            if kw.recommendation in [
                RecommendationType.STRONGLY_RECOMMEND,
                RecommendationType.RECOMMEND
            ]
        ]

        return recommended[:top_n]

    # ==============================================
    # 5ìœ„ ë³´ì¥ íŒì •
    # ==============================================

    def check_guaranteed_top5(
        self,
        scope: KeywordScope,
        raw_predicted_rank: int,
        adjusted_rank: int,
        safety_score: float,
        score_gap: float,
        top10_std: float,
        influencer_count: int,
        high_scorer_count: int
    ) -> Tuple[bool, List[str]]:
        """
        5ìœ„ ì´ë‚´ ìƒìœ„ë…¸ì¶œ ë³´ì¥ ì—¬ë¶€ íŒì •

        ë§¤ìš° ë³´ìˆ˜ì ì¸ ì¡°ê±´ìœ¼ë¡œ "í™•ì‹¤íˆ 5ìœ„ ì•ˆì— ë“¤ì–´ê°ˆ" í‚¤ì›Œë“œë§Œ ì„ ë³„

        ì¡°ê±´ (ëª¨ë‘ ë§Œì¡±í•´ì•¼ í•¨):
        1. ì§€ì—­ í‚¤ì›Œë“œ: ë³´ì • ìˆœìœ„ 3ìœ„ ì´ë‚´ ë˜ëŠ” ì›ë³¸ ìˆœìœ„ 1-2ìœ„
        2. ê´‘ì—­ í‚¤ì›Œë“œ: ë³´ì • ìˆœìœ„ 2ìœ„ ì´ë‚´ ë˜ëŠ” ì›ë³¸ ìˆœìœ„ 1ìœ„
        3. ì „êµ­ í‚¤ì›Œë“œ: ë³´ì • ìˆœìœ„ 1ìœ„ (ì›ë³¸ ìˆœìœ„ 1ìœ„ + ìµœì†Œ ë§ˆì§„)
        4. ì•ˆì „ ì ìˆ˜ 75ì  ì´ìƒ
        5. ì ìˆ˜ ì—¬ìœ  +5ì  ì´ìƒ
        6. ì¸í”Œë£¨ì–¸ì„œ 2ëª… ì´í•˜
        7. 70ì  ì´ìƒ ê³ ì ì 5ëª… ì´í•˜

        Returns:
            (is_guaranteed, reasons)
        """
        reasons = []
        is_guaranteed = True

        # 1. í‚¤ì›Œë“œ ë²”ìœ„ë³„ ìˆœìœ„ ì¡°ê±´
        if scope == KeywordScope.LOCAL:
            # ì§€ì—­: ë³´ì • 3ìœ„ ì´ë‚´ ë˜ëŠ” ì›ë³¸ 1-2ìœ„
            if adjusted_rank <= 3:
                reasons.append(f"âœ… ì§€ì—­ í‚¤ì›Œë“œ ë³´ì • {adjusted_rank}ìœ„ (3ìœ„ ì´ë‚´)")
            elif raw_predicted_rank <= 2:
                reasons.append(f"âœ… ì§€ì—­ í‚¤ì›Œë“œ ì›ë³¸ {raw_predicted_rank}ìœ„ (2ìœ„ ì´ë‚´)")
            else:
                reasons.append(f"âŒ ì§€ì—­ í‚¤ì›Œë“œì§€ë§Œ ìˆœìœ„ ì˜ˆì¸¡ì´ ë‚®ìŒ (ë³´ì • {adjusted_rank}ìœ„)")
                is_guaranteed = False

        elif scope == KeywordScope.REGIONAL:
            # ê´‘ì—­: ë³´ì • 2ìœ„ ì´ë‚´ ë˜ëŠ” ì›ë³¸ 1ìœ„
            if adjusted_rank <= 2:
                reasons.append(f"âœ… ê´‘ì—­ í‚¤ì›Œë“œ ë³´ì • {adjusted_rank}ìœ„ (2ìœ„ ì´ë‚´)")
            elif raw_predicted_rank == 1:
                reasons.append(f"âœ… ê´‘ì—­ í‚¤ì›Œë“œ ì›ë³¸ 1ìœ„")
            else:
                reasons.append(f"âŒ ê´‘ì—­ í‚¤ì›Œë“œ ìˆœìœ„ ì˜ˆì¸¡ì´ ë‚®ìŒ (ë³´ì • {adjusted_rank}ìœ„)")
                is_guaranteed = False

        else:  # NATIONAL
            # ì „êµ­: ë³´ì • 1ìœ„ë§Œ (ê°€ì¥ ë³´ìˆ˜ì )
            if adjusted_rank == 1:
                reasons.append(f"âœ… ì „êµ­ í‚¤ì›Œë“œ ë³´ì • 1ìœ„")
            elif raw_predicted_rank == 1 and adjusted_rank <= 2:
                reasons.append(f"âœ… ì „êµ­ í‚¤ì›Œë“œ ì›ë³¸ 1ìœ„ (ë³´ì • {adjusted_rank}ìœ„)")
            else:
                reasons.append(f"âŒ ì „êµ­ í‚¤ì›Œë“œëŠ” 1ìœ„ ì˜ˆì¸¡ë§Œ ë³´ì¥ (í˜„ì¬ ë³´ì • {adjusted_rank}ìœ„)")
                is_guaranteed = False

        # 2. ì•ˆì „ ì ìˆ˜ ì¡°ê±´ (75ì  ì´ìƒ)
        if safety_score >= 75:
            reasons.append(f"âœ… ì•ˆì „ ì ìˆ˜ {safety_score}ì  (75ì  ì´ìƒ)")
        else:
            reasons.append(f"âŒ ì•ˆì „ ì ìˆ˜ ë¶€ì¡± ({safety_score}ì  < 75ì )")
            is_guaranteed = False

        # 3. ì ìˆ˜ ì—¬ìœ  ì¡°ê±´ (+5ì  ì´ìƒ)
        if score_gap >= 5:
            reasons.append(f"âœ… ì ìˆ˜ ì—¬ìœ  +{score_gap:.1f}ì  (5ì  ì´ìƒ)")
        else:
            reasons.append(f"âŒ ì ìˆ˜ ì—¬ìœ  ë¶€ì¡± ({score_gap:.1f}ì  < 5ì )")
            is_guaranteed = False

        # 4. ì¸í”Œë£¨ì–¸ì„œ ì¡°ê±´ (2ëª… ì´í•˜)
        if influencer_count <= 2:
            reasons.append(f"âœ… ì¸í”Œë£¨ì–¸ì„œ {influencer_count}ëª… (2ëª… ì´í•˜)")
        else:
            reasons.append(f"âŒ ì¸í”Œë£¨ì–¸ì„œ ê³¼ë‹¤ ({influencer_count}ëª… > 2ëª…)")
            is_guaranteed = False

        # 5. ê³ ì ì ì¡°ê±´ (70ì  ì´ìƒ 5ëª… ì´í•˜)
        if high_scorer_count <= 5:
            reasons.append(f"âœ… ê³ ì ì(70+) {high_scorer_count}ëª… (5ëª… ì´í•˜)")
        else:
            reasons.append(f"âŒ ê³ ì ì ê³¼ë‹¤ ({high_scorer_count}ëª… > 5ëª…)")
            is_guaranteed = False

        # 6. ê²½ìŸ ì•ˆì •ì„± ì¡°ê±´ (í‘œì¤€í¸ì°¨ 12 ì´í•˜)
        if top10_std <= 12:
            reasons.append(f"âœ… ê²½ìŸ ì•ˆì •ì  (í‘œì¤€í¸ì°¨ {top10_std:.1f})")
        else:
            reasons.append(f"âš ï¸ ê²½ìŸ ë³€ë™ì„± ìˆìŒ (í‘œì¤€í¸ì°¨ {top10_std:.1f})")
            # ë³€ë™ì„±ì€ ê²½ê³ ë§Œ, ë³´ì¥ ì·¨ì†Œ ì•ˆ í•¨

        return is_guaranteed, reasons

    def get_guaranteed_top5_keywords(
        self,
        keywords_data: List[Dict],
        my_score: float,
        min_search_volume: int = 100
    ) -> List[SafetyAnalysis]:
        """
        5ìœ„ ë³´ì¥ í‚¤ì›Œë“œë§Œ í•„í„°ë§

        Args:
            keywords_data: í‚¤ì›Œë“œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            my_score: ë‚´ ë¸”ë¡œê·¸ ì ìˆ˜
            min_search_volume: ìµœì†Œ ê²€ìƒ‰ëŸ‰

        Returns:
            5ìœ„ ë³´ì¥ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì•ˆì „ ì ìˆ˜ ìˆœ)
        """
        guaranteed_keywords = []

        for kw_data in keywords_data:
            keyword = kw_data.get('keyword', '')
            top10_scores = kw_data.get('top10_scores', [])
            search_volume = kw_data.get('search_volume', 0)
            influencer_count = kw_data.get('influencer_count', 0)

            # ê²€ìƒ‰ëŸ‰ í•„í„°
            if search_volume < min_search_volume:
                continue

            # ì•ˆì „ì„± ë¶„ì„
            analysis = self.analyze_keyword_safety(
                keyword=keyword,
                my_score=my_score,
                top10_scores=top10_scores,
                search_volume=search_volume,
                influencer_count=influencer_count
            )

            # 5ìœ„ ë³´ì¥ í‚¤ì›Œë“œë§Œ ì¶”ê°€
            if analysis.is_guaranteed_top5:
                guaranteed_keywords.append(analysis)

        # ì•ˆì „ ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        guaranteed_keywords.sort(key=lambda x: x.safety_score, reverse=True)

        return guaranteed_keywords


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
safe_keyword_selector = SafeKeywordSelector()


# ==============================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================

def analyze_keyword_for_blog(
    keyword: str,
    blog_score: float,
    top10_scores: List[float],
    search_volume: int = 0,
    influencer_count: int = 0,
    top10_blog_names: List[str] = None
) -> Dict:
    """
    ë¸”ë¡œê·¸ ê¸°ì¤€ í‚¤ì›Œë“œ ì•ˆì „ì„± ë¶„ì„ (APIìš© í—¬í¼)

    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    analysis = safe_keyword_selector.analyze_keyword_safety(
        keyword=keyword,
        my_score=blog_score,
        top10_scores=top10_scores,
        search_volume=search_volume,
        influencer_count=influencer_count,
        top10_blog_names=top10_blog_names
    )

    return {
        'keyword': analysis.keyword,
        'scope': analysis.scope.value,
        'predicted_rank': {
            'raw': analysis.raw_predicted_rank,
            'safety_margin': analysis.safety_margin,
            'adjusted': analysis.adjusted_rank
        },
        'scores': {
            'my_score': analysis.my_score,
            'top10_avg': analysis.top10_avg,
            'top10_min': analysis.top10_min,
            'score_gap': analysis.score_gap,
            'score_buffer_percent': analysis.score_buffer
        },
        'competition': {
            'top10_std': analysis.top10_std,
            'influencer_count': analysis.influencer_count,
            'high_scorer_count': analysis.high_scorer_count
        },
        'safety': {
            'score': analysis.safety_score,
            'grade': analysis.safety_grade.value,
            'confidence': analysis.confidence
        },
        'recommendation': {
            'type': analysis.recommendation.value,
            'reasons': analysis.reasons,
            'tips': analysis.tips
        },
        'search_volume': analysis.search_volume,
        'warnings': analysis.warnings,
        # 5ìœ„ ë³´ì¥ ì—¬ë¶€
        'guaranteed_top5': {
            'is_guaranteed': analysis.is_guaranteed_top5,
            'reasons': analysis.guaranteed_top5_reasons
        },
        # ì‹ ê·œ í•„ë“œë“¤
        'search_intent': analysis.search_intent.value,
        'is_brand_keyword': analysis.is_brand_keyword,
        'official_blog': {
            'detected': analysis.has_official_blog,
            'rank': analysis.official_blog_rank
        }
    }
