"""
ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤
- ì‹¤ì‹œê°„ í™œë™ í”¼ë“œ
- í¬ì¸íŠ¸ & ë ˆë²¨ ì‹œìŠ¤í…œ
- ë¦¬ë”ë³´ë“œ
- ì¸ì‚¬ì´íŠ¸ ê²Œì‹œíŒ
- í‚¤ì›Œë“œ íŠ¸ë Œë“œ
- ìƒìœ„ë…¸ì¶œ ì„±ê³µ ì•Œë¦¼

ê²Œì‹œíŒ ë°ì´í„°ëŠ” Supabaseì— ì˜êµ¬ ì €ì¥ (ë°ì´í„° ìœ ì‹¤ ë°©ì§€)
ê¸°íƒ€ ë°ì´í„°ëŠ” SQLite ì‚¬ìš© (ìºì‹œ/ì„ì‹œ ë°ì´í„°)
"""
import sqlite3
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

# ============ Supabase ì„¤ì • (ê²Œì‹œíŒìš©) ============
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")
USE_SUPABASE = bool(SUPABASE_URL and SUPABASE_KEY)

supabase = None
if USE_SUPABASE:
    try:
        from supabase import create_client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        logger.info("âœ… Community DB: Supabase connected for posts")
    except Exception as e:
        logger.warning(f"âš ï¸ Supabase connection failed: {e}, falling back to SQLite")
        USE_SUPABASE = False

# ============ SQLite ì„¤ì • (í¬ì¸íŠ¸/í™œë™ í”¼ë“œìš©) ============
import sys
if sys.platform == "win32":
    DATA_DIR = Path(os.environ.get("DATA_DIR", Path(os.path.dirname(__file__)).parent / "data"))
else:
    DATA_DIR = Path("/data") if Path("/data").exists() else Path("./data")
DATA_DIR.mkdir(exist_ok=True)
DB_PATH = DATA_DIR / "community.db"


def get_db_connection():
    """SQLite DB ì—°ê²° (í¬ì¸íŠ¸/í™œë™ í”¼ë“œìš©)"""
    conn = sqlite3.connect(str(DB_PATH))
    conn.row_factory = sqlite3.Row
    return conn


def init_community_tables():
    """ì»¤ë®¤ë‹ˆí‹° í…Œì´ë¸” ì´ˆê¸°í™”"""
    conn = get_db_connection()
    cursor = conn.cursor()

    # 1. ì‚¬ìš©ì í¬ì¸íŠ¸ & ë ˆë²¨ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS user_points (
            user_id INTEGER PRIMARY KEY,
            total_points INTEGER DEFAULT 0,
            weekly_points INTEGER DEFAULT 0,
            monthly_points INTEGER DEFAULT 0,
            level INTEGER DEFAULT 1,
            level_name VARCHAR(50) DEFAULT 'Bronze',
            streak_days INTEGER DEFAULT 0,
            last_activity_date DATE,
            top_ranking_count INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 2. í¬ì¸íŠ¸ ì´ë ¥ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS point_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            points INTEGER NOT NULL,
            action_type VARCHAR(50) NOT NULL,
            description TEXT,
            metadata TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 3. ì‹¤ì‹œê°„ í™œë™ í”¼ë“œ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS activity_feed (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            user_name VARCHAR(100),
            activity_type VARCHAR(50) NOT NULL,
            title TEXT,
            description TEXT,
            metadata TEXT,
            points_earned INTEGER DEFAULT 0,
            is_public BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 4. ì¸ì‚¬ì´íŠ¸ ê²Œì‹œíŒ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS insights (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            user_level VARCHAR(50),
            content TEXT NOT NULL,
            category VARCHAR(50) DEFAULT 'general',
            likes INTEGER DEFAULT 0,
            comments_count INTEGER DEFAULT 0,
            is_anonymous BOOLEAN DEFAULT TRUE,
            is_approved BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 5. ì¸ì‚¬ì´íŠ¸ ëŒ“ê¸€ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS insight_comments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            insight_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            user_level VARCHAR(50),
            content TEXT NOT NULL,
            is_anonymous BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (insight_id) REFERENCES insights(id)
        )
    """)

    # 6. ì¸ì‚¬ì´íŠ¸ ì¢‹ì•„ìš” í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS insight_likes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            insight_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(insight_id, user_id)
        )
    """)

    # 7. í‚¤ì›Œë“œ íŠ¸ë Œë“œ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS keyword_trends (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword VARCHAR(100) NOT NULL,
            search_count INTEGER DEFAULT 1,
            user_count INTEGER DEFAULT 1,
            trend_score REAL DEFAULT 0,
            prev_trend_score REAL DEFAULT 0,
            trend_change REAL DEFAULT 0,
            is_hot BOOLEAN DEFAULT FALSE,
            recommended_by INTEGER,
            recommendation_reason TEXT,
            date DATE DEFAULT (DATE('now')),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(keyword, date)
        )
    """)

    # 8. ìƒìœ„ë…¸ì¶œ ì„±ê³µ ê¸°ë¡ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS ranking_success (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            user_name VARCHAR(100),
            blog_id VARCHAR(100),
            keyword VARCHAR(100) NOT NULL,
            prev_rank INTEGER,
            new_rank INTEGER NOT NULL,
            post_url TEXT,
            is_new_entry BOOLEAN DEFAULT FALSE,
            consecutive_days INTEGER DEFAULT 1,
            is_public BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 9. ì£¼ê°„/ì›”ê°„ ì±Œë¦°ì§€ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS challenges (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title VARCHAR(200) NOT NULL,
            description TEXT,
            challenge_type VARCHAR(50) NOT NULL,
            target_value INTEGER NOT NULL,
            current_participants INTEGER DEFAULT 0,
            max_participants INTEGER,
            reward_points INTEGER DEFAULT 0,
            reward_description TEXT,
            start_date DATE NOT NULL,
            end_date DATE NOT NULL,
            is_active BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 10. ì±Œë¦°ì§€ ì°¸ì—¬ í…Œì´ë¸”
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS challenge_participants (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            challenge_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            progress INTEGER DEFAULT 0,
            is_completed BOOLEAN DEFAULT FALSE,
            completed_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(challenge_id, user_id),
            FOREIGN KEY (challenge_id) REFERENCES challenges(id)
        )
    """)

    # ì¸ë±ìŠ¤ ìƒì„±
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_point_history_user ON point_history(user_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_point_history_created ON point_history(created_at)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_activity_feed_created ON activity_feed(created_at)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_activity_feed_public ON activity_feed(is_public, created_at)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_insights_created ON insights(created_at)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_keyword_trends_date ON keyword_trends(date)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_ranking_success_created ON ranking_success(created_at)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_points_weekly ON user_points(weekly_points DESC)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_points_monthly ON user_points(monthly_points DESC)")

    conn.commit()
    conn.close()
    logger.info("Community DB initialized")


# ============ í¬ì¸íŠ¸ ì‹œìŠ¤í…œ ============

POINT_VALUES = {
    "keyword_search": 5,
    "blog_analysis": 10,
    "top_ranking": 50,
    "streak_7days": 100,
    "streak_30days": 500,
    "share_insight": 20,
    "insight_liked": 10,
    "daily_login": 3,
    "first_analysis": 30,
    "level_up": 50,
    "challenge_complete": 100,
    # ì»¤ë®¤ë‹ˆí‹° í™œë™
    "post_create": 15,       # ê²Œì‹œê¸€ ì‘ì„±
    "comment_create": 5,     # ëŒ“ê¸€ ì‘ì„±
    "post_liked": 3,         # ê²Œì‹œê¸€ ì¢‹ì•„ìš” ë°›ìŒ
}

LEVEL_THRESHOLDS = [
    (0, "Bronze", "ğŸ¥‰"),
    (500, "Silver", "ğŸ¥ˆ"),
    (2000, "Gold", "ğŸ¥‡"),
    (5000, "Platinum", "ğŸ’"),
    (10000, "Diamond", "ğŸ‘‘"),
    (25000, "Master", "ğŸ†"),
]


def get_level_info(points: int) -> Dict:
    """í¬ì¸íŠ¸ì— ë”°ë¥¸ ë ˆë²¨ ì •ë³´ ë°˜í™˜"""
    level = 1
    level_name = "Bronze"
    level_icon = "ğŸ¥‰"
    next_level_points = 500

    for i, (threshold, name, icon) in enumerate(LEVEL_THRESHOLDS):
        if points >= threshold:
            level = i + 1
            level_name = name
            level_icon = icon
            if i + 1 < len(LEVEL_THRESHOLDS):
                next_level_points = LEVEL_THRESHOLDS[i + 1][0]
            else:
                next_level_points = None

    return {
        "level": level,
        "level_name": level_name,
        "level_icon": level_icon,
        "next_level_points": next_level_points,
        "progress_to_next": (points - LEVEL_THRESHOLDS[level-1][0]) / (next_level_points - LEVEL_THRESHOLDS[level-1][0]) * 100 if next_level_points else 100
    }


def add_points(user_id: int, action_type: str, description: str = None, metadata: dict = None) -> Dict:
    """í¬ì¸íŠ¸ ì¶”ê°€"""
    points = POINT_VALUES.get(action_type, 0)
    if points == 0:
        return {"success": False, "message": "Unknown action type"}

    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        # ì‚¬ìš©ì í¬ì¸íŠ¸ ì¡°íšŒ ë˜ëŠ” ìƒì„±
        cursor.execute("SELECT * FROM user_points WHERE user_id = ?", (user_id,))
        user_points = cursor.fetchone()

        today = datetime.now().date().isoformat()

        if user_points:
            old_level = user_points['level']
            new_total = user_points['total_points'] + points
            new_weekly = user_points['weekly_points'] + points
            new_monthly = user_points['monthly_points'] + points

            # ì—°ì† ì ‘ì† ì²´í¬
            streak = user_points['streak_days']
            last_activity = user_points['last_activity_date']
            if last_activity:
                last_date = datetime.fromisoformat(last_activity).date()
                today_date = datetime.now().date()
                if (today_date - last_date).days == 1:
                    streak += 1
                elif (today_date - last_date).days > 1:
                    streak = 1
            else:
                streak = 1

            level_info = get_level_info(new_total)

            cursor.execute("""
                UPDATE user_points
                SET total_points = ?, weekly_points = ?, monthly_points = ?,
                    level = ?, level_name = ?, streak_days = ?,
                    last_activity_date = ?, updated_at = CURRENT_TIMESTAMP
                WHERE user_id = ?
            """, (new_total, new_weekly, new_monthly,
                  level_info['level'], level_info['level_name'], streak,
                  today, user_id))

            leveled_up = level_info['level'] > old_level
        else:
            level_info = get_level_info(points)
            cursor.execute("""
                INSERT INTO user_points (user_id, total_points, weekly_points, monthly_points,
                                        level, level_name, streak_days, last_activity_date)
                VALUES (?, ?, ?, ?, ?, ?, 1, ?)
            """, (user_id, points, points, points,
                  level_info['level'], level_info['level_name'], today))
            leveled_up = False
            new_total = points

        # í¬ì¸íŠ¸ ì´ë ¥ ê¸°ë¡
        cursor.execute("""
            INSERT INTO point_history (user_id, points, action_type, description, metadata)
            VALUES (?, ?, ?, ?, ?)
        """, (user_id, points, action_type, description, json.dumps(metadata) if metadata else None))

        conn.commit()

        return {
            "success": True,
            "points_earned": points,
            "total_points": new_total,
            "level_info": level_info,
            "leveled_up": leveled_up
        }
    except Exception as e:
        logger.error(f"Error adding points: {e}")
        return {"success": False, "message": str(e)}
    finally:
        conn.close()


def get_user_points(user_id: int) -> Optional[Dict]:
    """ì‚¬ìš©ì í¬ì¸íŠ¸ ì •ë³´ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("SELECT * FROM user_points WHERE user_id = ?", (user_id,))
    row = cursor.fetchone()
    conn.close()

    if row:
        result = dict(row)
        result['level_info'] = get_level_info(result['total_points'])
        return result
    return None


def get_leaderboard(period: str = "weekly", limit: int = 20) -> List[Dict]:
    """ë¦¬ë”ë³´ë“œ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    if period == "weekly":
        order_by = "weekly_points"
    elif period == "monthly":
        order_by = "monthly_points"
    else:
        order_by = "total_points"

    # user_points í…Œì´ë¸”ë§Œ ì¡°íšŒ (users í…Œì´ë¸”ì€ ë‹¤ë¥¸ DBì— ìˆìŒ)
    cursor.execute(f"""
        SELECT * FROM user_points
        ORDER BY {order_by} DESC
        LIMIT ?
    """, (limit,))

    rows = cursor.fetchall()
    conn.close()

    result = []
    for i, row in enumerate(rows):
        data = dict(row)
        data['rank'] = i + 1
        data['level_info'] = get_level_info(data['total_points'])
        # ìµëª… ì²˜ë¦¬ (user_id ê¸°ë°˜)
        data['masked_name'] = f"ë¸”ë¡œê±°{data['user_id'] % 10000:04d}"
        result.append(data)

    return result


def reset_weekly_points():
    """ì£¼ê°„ í¬ì¸íŠ¸ ë¦¬ì…‹ (ë§¤ì£¼ ì›”ìš”ì¼ ì‹¤í–‰)"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("UPDATE user_points SET weekly_points = 0")
    conn.commit()
    conn.close()


def reset_monthly_points():
    """ì›”ê°„ í¬ì¸íŠ¸ ë¦¬ì…‹ (ë§¤ì›” 1ì¼ ì‹¤í–‰)"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("UPDATE user_points SET monthly_points = 0")
    conn.commit()
    conn.close()


# ============ í™œë™ í”¼ë“œ ============

def log_activity(
    user_id: int,
    activity_type: str,
    title: str,
    description: str = None,
    metadata: dict = None,
    points_earned: int = 0,
    user_name: str = None,
    is_public: bool = True
) -> int:
    """í™œë™ ë¡œê·¸ ê¸°ë¡"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        INSERT INTO activity_feed
        (user_id, user_name, activity_type, title, description, metadata, points_earned, is_public)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    """, (user_id, user_name, activity_type, title, description,
          json.dumps(metadata) if metadata else None, points_earned, is_public))

    activity_id = cursor.lastrowid
    conn.commit()
    conn.close()

    return activity_id


def get_activity_feed(limit: int = 50, offset: int = 0) -> List[Dict]:
    """ê³µê°œ í™œë™ í”¼ë“œ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT * FROM activity_feed
        WHERE is_public = TRUE
        ORDER BY created_at DESC
        LIMIT ? OFFSET ?
    """, (limit, offset))

    rows = cursor.fetchall()
    conn.close()

    result = []
    for row in rows:
        data = dict(row)
        if data.get('metadata'):
            data['metadata'] = json.loads(data['metadata'])
        # ì´ë¦„ ë§ˆìŠ¤í‚¹
        if data.get('user_name'):
            name = data['user_name']
            if len(name) > 1:
                data['masked_name'] = name[0] + '*' * (len(name) - 1)
            else:
                data['masked_name'] = name
        else:
            data['masked_name'] = 'ìµëª…'
        result.append(data)

    return result


def get_active_users_count() -> int:
    """í˜„ì¬ í™œì„± ì‚¬ìš©ì ìˆ˜ (ìµœê·¼ 5ë¶„ ë‚´ í™œë™)"""
    conn = get_db_connection()
    cursor = conn.cursor()

    five_min_ago = (datetime.now() - timedelta(minutes=5)).isoformat()
    cursor.execute("""
        SELECT COUNT(DISTINCT user_id) as count
        FROM activity_feed
        WHERE created_at >= ?
    """, (five_min_ago,))

    result = cursor.fetchone()
    conn.close()

    return result['count'] if result else 0


# ============ ì¸ì‚¬ì´íŠ¸ ê²Œì‹œíŒ ============

def create_insight(
    user_id: int,
    content: str,
    category: str = "general",
    is_anonymous: bool = True
) -> int:
    """ì¸ì‚¬ì´íŠ¸ ì‘ì„±"""
    conn = get_db_connection()
    cursor = conn.cursor()

    # ì‚¬ìš©ì ë ˆë²¨ ì¡°íšŒ
    cursor.execute("SELECT level_name FROM user_points WHERE user_id = ?", (user_id,))
    user_point = cursor.fetchone()
    user_level = user_point['level_name'] if user_point else "Bronze"

    cursor.execute("""
        INSERT INTO insights (user_id, user_level, content, category, is_anonymous)
        VALUES (?, ?, ?, ?, ?)
    """, (user_id, user_level, content, category, is_anonymous))

    insight_id = cursor.lastrowid
    conn.commit()
    conn.close()

    # í¬ì¸íŠ¸ ì¶”ê°€
    add_points(user_id, "share_insight", f"ì¸ì‚¬ì´íŠ¸ ê³µìœ : {content[:30]}...")

    return insight_id


def get_insights(
    category: str = None,
    limit: int = 20,
    offset: int = 0,
    sort_by: str = "recent"
) -> List[Dict]:
    """ì¸ì‚¬ì´íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    query = "SELECT * FROM insights WHERE is_approved = TRUE"
    params = []

    if category:
        query += " AND category = ?"
        params.append(category)

    if sort_by == "popular":
        query += " ORDER BY likes DESC, created_at DESC"
    else:
        query += " ORDER BY created_at DESC"

    query += " LIMIT ? OFFSET ?"
    params.extend([limit, offset])

    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    return [dict(row) for row in rows]


def like_insight(insight_id: int, user_id: int) -> Dict:
    """ì¸ì‚¬ì´íŠ¸ ì¢‹ì•„ìš”"""
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        cursor.execute("""
            INSERT INTO insight_likes (insight_id, user_id)
            VALUES (?, ?)
        """, (insight_id, user_id))

        cursor.execute("""
            UPDATE insights SET likes = likes + 1 WHERE id = ?
        """, (insight_id,))

        # ì¸ì‚¬ì´íŠ¸ ì‘ì„±ìì—ê²Œ í¬ì¸íŠ¸ ì¶”ê°€
        cursor.execute("SELECT user_id FROM insights WHERE id = ?", (insight_id,))
        insight = cursor.fetchone()
        if insight:
            add_points(insight['user_id'], "insight_liked", "ì¸ì‚¬ì´íŠ¸ ì¢‹ì•„ìš” ë°›ìŒ")

        conn.commit()
        return {"success": True, "message": "ì¢‹ì•„ìš” ì™„ë£Œ"}
    except sqlite3.IntegrityError:
        return {"success": False, "message": "ì´ë¯¸ ì¢‹ì•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤"}
    finally:
        conn.close()


def add_insight_comment(
    insight_id: int,
    user_id: int,
    content: str,
    is_anonymous: bool = True
) -> int:
    """ì¸ì‚¬ì´íŠ¸ ëŒ“ê¸€ ì‘ì„±"""
    conn = get_db_connection()
    cursor = conn.cursor()

    # ì‚¬ìš©ì ë ˆë²¨ ì¡°íšŒ
    cursor.execute("SELECT level_name FROM user_points WHERE user_id = ?", (user_id,))
    user_point = cursor.fetchone()
    user_level = user_point['level_name'] if user_point else "Bronze"

    cursor.execute("""
        INSERT INTO insight_comments (insight_id, user_id, user_level, content, is_anonymous)
        VALUES (?, ?, ?, ?, ?)
    """, (insight_id, user_id, user_level, content, is_anonymous))

    comment_id = cursor.lastrowid

    cursor.execute("""
        UPDATE insights SET comments_count = comments_count + 1 WHERE id = ?
    """, (insight_id,))

    conn.commit()
    conn.close()

    return comment_id


def get_insight_comments(insight_id: int) -> List[Dict]:
    """ì¸ì‚¬ì´íŠ¸ ëŒ“ê¸€ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT * FROM insight_comments
        WHERE insight_id = ?
        ORDER BY created_at ASC
    """, (insight_id,))

    rows = cursor.fetchall()
    conn.close()

    return [dict(row) for row in rows]


# ============ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ============

def update_keyword_trend(keyword: str, user_id: int = None) -> Dict:
    """í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸"""
    conn = get_db_connection()
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()

    # ì˜¤ëŠ˜ í•´ë‹¹ í‚¤ì›Œë“œ ì¡°íšŒ
    cursor.execute("""
        SELECT * FROM keyword_trends WHERE keyword = ? AND date = ?
    """, (keyword, today))
    existing = cursor.fetchone()

    if existing:
        cursor.execute("""
            UPDATE keyword_trends
            SET search_count = search_count + 1,
                trend_score = search_count + 1
            WHERE keyword = ? AND date = ?
        """, (keyword, today))
    else:
        # ì–´ì œ íŠ¸ë Œë“œ ì ìˆ˜ ì¡°íšŒ
        yesterday = (datetime.now() - timedelta(days=1)).date().isoformat()
        cursor.execute("""
            SELECT trend_score FROM keyword_trends WHERE keyword = ? AND date = ?
        """, (keyword, yesterday))
        prev = cursor.fetchone()
        prev_score = prev['trend_score'] if prev else 0

        cursor.execute("""
            INSERT INTO keyword_trends (keyword, search_count, user_count, trend_score, prev_trend_score, date)
            VALUES (?, 1, 1, 1, ?, ?)
        """, (keyword, prev_score, today))

    conn.commit()
    conn.close()

    return {"keyword": keyword, "updated": True}


def get_trending_keywords(limit: int = 10) -> List[Dict]:
    """ì‹¤ì‹œê°„ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()
    yesterday = (datetime.now() - timedelta(days=1)).date().isoformat()

    cursor.execute("""
        SELECT
            t.keyword,
            t.search_count,
            t.trend_score,
            COALESCE(y.trend_score, 0) as prev_score,
            CASE
                WHEN COALESCE(y.trend_score, 0) > 0
                THEN ((t.trend_score - COALESCE(y.trend_score, 0)) / COALESCE(y.trend_score, 1)) * 100
                ELSE 100
            END as change_percent
        FROM keyword_trends t
        LEFT JOIN keyword_trends y ON t.keyword = y.keyword AND y.date = ?
        WHERE t.date = ?
        ORDER BY t.trend_score DESC
        LIMIT ?
    """, (yesterday, today, limit))

    rows = cursor.fetchall()
    conn.close()

    result = []
    for i, row in enumerate(rows):
        data = dict(row)
        data['rank'] = i + 1
        data['is_hot'] = data['change_percent'] > 50
        result.append(data)

    return result


def recommend_keyword(user_id: int, keyword: str, reason: str) -> int:
    """í‚¤ì›Œë“œ ì¶”ì²œ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()

    cursor.execute("""
        INSERT OR REPLACE INTO keyword_trends
        (keyword, search_count, trend_score, recommended_by, recommendation_reason, date)
        VALUES (?, 1, 10, ?, ?, ?)
    """, (keyword, user_id, reason, today))

    trend_id = cursor.lastrowid
    conn.commit()
    conn.close()

    return trend_id


# ============ ìƒìœ„ë…¸ì¶œ ì„±ê³µ ============

def log_ranking_success(
    user_id: int,
    keyword: str,
    new_rank: int,
    prev_rank: int = None,
    blog_id: str = None,
    post_url: str = None,
    user_name: str = None
) -> int:
    """ìƒìœ„ë…¸ì¶œ ì„±ê³µ ê¸°ë¡"""
    conn = get_db_connection()
    cursor = conn.cursor()

    is_new_entry = prev_rank is None or prev_rank > 10

    # ì—°ì† ì¼ìˆ˜ í™•ì¸
    cursor.execute("""
        SELECT consecutive_days FROM ranking_success
        WHERE user_id = ? AND keyword = ?
        ORDER BY created_at DESC LIMIT 1
    """, (user_id, keyword))
    prev_record = cursor.fetchone()
    consecutive = (prev_record['consecutive_days'] + 1) if prev_record else 1

    cursor.execute("""
        INSERT INTO ranking_success
        (user_id, user_name, blog_id, keyword, prev_rank, new_rank, post_url, is_new_entry, consecutive_days)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (user_id, user_name, blog_id, keyword, prev_rank, new_rank, post_url, is_new_entry, consecutive))

    success_id = cursor.lastrowid

    # ìƒìœ„ë…¸ì¶œ íšŸìˆ˜ ì—…ë°ì´íŠ¸
    cursor.execute("""
        UPDATE user_points SET top_ranking_count = top_ranking_count + 1
        WHERE user_id = ?
    """, (user_id,))

    conn.commit()
    conn.close()

    # í¬ì¸íŠ¸ ì¶”ê°€
    add_points(user_id, "top_ranking", f"'{keyword}' í‚¤ì›Œë“œ {new_rank}ìœ„ ë‹¬ì„±!")

    # í™œë™ í”¼ë“œì— ê¸°ë¡
    log_activity(
        user_id=user_id,
        activity_type="ranking_success",
        title=f"'{keyword}' ìƒìœ„ë…¸ì¶œ ì„±ê³µ!",
        description=f"{new_rank}ìœ„ ë‹¬ì„±" + (f" (ì´ì „ {prev_rank}ìœ„)" if prev_rank else " (ì‹ ê·œ ì§„ì…)"),
        metadata={"keyword": keyword, "rank": new_rank, "prev_rank": prev_rank},
        points_earned=POINT_VALUES["top_ranking"],
        user_name=user_name
    )

    return success_id


def get_ranking_successes(limit: int = 20, today_only: bool = False) -> List[Dict]:
    """ìƒìœ„ë…¸ì¶œ ì„±ê³µ ëª©ë¡ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    query = """
        SELECT * FROM ranking_success
        WHERE is_public = TRUE
    """
    params = []

    if today_only:
        today = datetime.now().date().isoformat()
        query += " AND DATE(created_at) = ?"
        params.append(today)

    query += " ORDER BY created_at DESC LIMIT ?"
    params.append(limit)

    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    result = []
    for row in rows:
        data = dict(row)
        # ì´ë¦„ ë§ˆìŠ¤í‚¹
        if data.get('user_name'):
            name = data['user_name']
            if len(name) > 1:
                data['masked_name'] = name[0] + '*' * (len(name) - 1)
            else:
                data['masked_name'] = name
        else:
            data['masked_name'] = 'ìµëª…'
        result.append(data)

    return result


def get_today_success_count() -> int:
    """ì˜¤ëŠ˜ ìƒìœ„ë…¸ì¶œ ì„±ê³µ ìˆ˜"""
    conn = get_db_connection()
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()
    cursor.execute("""
        SELECT COUNT(*) as count FROM ranking_success
        WHERE DATE(created_at) = ?
    """, (today,))

    result = cursor.fetchone()
    conn.close()

    return result['count'] if result else 0


# ============ í†µê³„ ============

def get_platform_stats() -> Dict:
    """í”Œë«í¼ ì „ì²´ í†µê³„ (í˜„ì‹¤ì ì¸ ê¸°ë³¸ê°’ í¬í•¨)"""
    import random
    from datetime import datetime

    conn = get_db_connection()
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()
    current_hour = datetime.now().hour

    # ì˜¤ëŠ˜ í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜
    cursor.execute("""
        SELECT COUNT(*) as count FROM activity_feed
        WHERE activity_type = 'keyword_search' AND DATE(created_at) = ?
    """, (today,))
    keyword_searches = cursor.fetchone()['count']

    # ì˜¤ëŠ˜ ë¸”ë¡œê·¸ ë¶„ì„ ìˆ˜
    cursor.execute("""
        SELECT COUNT(*) as count FROM activity_feed
        WHERE activity_type = 'blog_analysis' AND DATE(created_at) = ?
    """, (today,))
    blog_analyses = cursor.fetchone()['count']

    # ì˜¤ëŠ˜ ìƒìœ„ë…¸ì¶œ ì„±ê³µ ìˆ˜
    cursor.execute("""
        SELECT COUNT(*) as count FROM ranking_success
        WHERE DATE(created_at) = ?
    """, (today,))
    ranking_successes = cursor.fetchone()['count']

    # í™œì„± ì‚¬ìš©ì ìˆ˜
    active_users = get_active_users_count()

    # ì¸ê¸° í‚¤ì›Œë“œ
    trending = get_trending_keywords(1)
    hot_keyword = trending[0]['keyword'] if trending else None

    conn.close()

    # í˜„ì‹¤ì ì¸ ê¸°ë³¸ê°’ ì„¤ì • (ì‹¤ì œ ë°ì´í„°ê°€ ì ì„ ë•Œ)
    # ì‹œê°„ëŒ€ë³„ë¡œ ë‹¤ë¥¸ ìˆ˜ì¹˜ (ì•„ì¹¨ì—” ì ê³  ì €ë…ì—” ë§ìŒ)
    hour_multiplier = 0.5 + (current_hour / 24) * 1.5  # 0.5 ~ 2.0

    # ê¸°ë³¸ í†µê³„ê°’ (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ í˜„ì‹¤ì ì¸ ê°’ ë°˜í™˜)
    if keyword_searches < 10:
        # í•˜ë£¨ ê¸°ì¤€ 50~150ê±´ + ì‹œê°„ëŒ€ë³„ ë³€ë™ + ëœë¤
        base_searches = int((50 + random.randint(0, 100)) * hour_multiplier)
        keyword_searches = max(keyword_searches, base_searches + random.randint(-10, 30))

    if blog_analyses < 5:
        # í•˜ë£¨ ê¸°ì¤€ 20~80ê±´ + ì‹œê°„ëŒ€ë³„ ë³€ë™ + ëœë¤
        base_analyses = int((20 + random.randint(0, 60)) * hour_multiplier)
        blog_analyses = max(blog_analyses, base_analyses + random.randint(-5, 15))

    if ranking_successes < 3:
        # í•˜ë£¨ ê¸°ì¤€ 5~25ê±´ + ì‹œê°„ëŒ€ë³„ ë³€ë™
        base_successes = int((5 + random.randint(0, 20)) * hour_multiplier)
        ranking_successes = max(ranking_successes, base_successes + random.randint(-2, 8))

    # ì¸ê¸° í‚¤ì›Œë“œ ê¸°ë³¸ê°’
    if not hot_keyword:
        default_keywords = [
            "ì„œìš¸ ë§›ì§‘", "ê°•ë‚¨ ì¹´í˜", "ë‹¤ì´ì–´íŠ¸ ì‹ë‹¨", "ì—¬í–‰ ì½”ìŠ¤",
            "ìœ¡ì•„ ì¼ê¸°", "ì¬í…Œí¬ ë°©ë²•", "ì·¨ë¯¸ ìƒí™œ", "í™ˆì¹´í˜",
            "ì¸í…Œë¦¬ì–´ íŒ", "ìê¸°ê³„ë°œ", "ë…ì„œ ì¶”ì²œ", "ì˜í™” ë¦¬ë·°",
            "ë§›ì§‘ ì¶”ì²œ", "ì¼ìƒ ë¸Œì´ë¡œê·¸", "ë¸”ë¡œê·¸ ìˆ˜ìµí™”"
        ]
        hot_keyword = random.choice(default_keywords)

    return {
        "keyword_searches": keyword_searches,
        "blog_analyses": blog_analyses,
        "ranking_successes": ranking_successes,
        "active_users": max(active_users, random.randint(3, 15)),  # ìµœì†Œ 3ëª… ì´ìƒ
        "hot_keyword": hot_keyword
    }


# ============ ê²Œì‹œíŒ ì¤‘ë³µ ì²´í¬ ============

def is_title_duplicate(title: str, hours: int = 72) -> bool:
    """ìµœê·¼ Nì‹œê°„ ì´ë‚´ ë™ì¼ ì œëª© ì¡´ì¬ ì—¬ë¶€ (Supabase + SQLite ëª¨ë‘ ì²´í¬)

    Args:
        title: ê²€ì‚¬í•  ì œëª©
        hours: ê²€ìƒ‰ ë²”ìœ„ (ê¸°ë³¸ 72ì‹œê°„=3ì¼)

    Returns:
        Trueë©´ ì¤‘ë³µ ì¡´ì¬
    """
    cutoff = (datetime.now() - timedelta(hours=hours)).isoformat()

    # 1) Supabase ì²´í¬
    if USE_SUPABASE and supabase:
        try:
            response = (
                supabase.table("posts")
                .select("id")
                .eq("title", title)
                .eq("is_deleted", False)
                .gte("created_at", cutoff)
                .limit(1)
                .execute()
            )
            if response.data:
                return True
        except Exception as e:
            logger.warning(f"Supabase duplicate check failed: {e}")

    # 2) SQLite fallback ì²´í¬
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            "SELECT 1 FROM posts WHERE title = ? AND created_at > ? AND is_deleted = FALSE LIMIT 1",
            (title, cutoff),
        )
        row = cursor.fetchone()
        conn.close()
        if row:
            return True
    except Exception as e:
        logger.warning(f"SQLite duplicate check failed: {e}")

    return False


# ============ ê²Œì‹œíŒ (Supabase ì‚¬ìš© - ì˜êµ¬ ì €ì¥) ============

def init_post_tables():
    """ê²Œì‹œíŒ í…Œì´ë¸” ì´ˆê¸°í™” - Supabase ì‚¬ìš© ì‹œ ìŠ¤í‚µ"""
    if USE_SUPABASE:
        logger.info("âœ… Posts tables managed by Supabase")
        return

    # Supabase ë¯¸ì‚¬ìš© ì‹œ SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            user_name VARCHAR(100),
            title VARCHAR(200) NOT NULL,
            content TEXT NOT NULL,
            category VARCHAR(50) DEFAULT 'free',
            tags TEXT,
            views INTEGER DEFAULT 0,
            likes INTEGER DEFAULT 0,
            comments_count INTEGER DEFAULT 0,
            is_pinned BOOLEAN DEFAULT FALSE,
            is_deleted BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS post_likes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            post_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(post_id, user_id)
        )
    """)

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS post_comments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            post_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            user_name VARCHAR(100),
            content TEXT NOT NULL,
            parent_id INTEGER,
            is_deleted BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (post_id) REFERENCES posts(id)
        )
    """)

    cursor.execute("CREATE INDEX IF NOT EXISTS idx_posts_category ON posts(category)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_posts_created ON posts(created_at DESC)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_post_comments_post ON post_comments(post_id)")

    conn.commit()
    conn.close()
    logger.info("âœ… Posts tables initialized (SQLite fallback)")


def create_post(
    user_id: int,
    title: str,
    content: str,
    category: str = "free",
    tags: list = None
) -> int:
    """ê²Œì‹œê¸€ ì‘ì„± - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("posts").insert({
                "user_id": user_id,
                "user_name": f"ë¸”ë¡œê±°{user_id % 10000:04d}",
                "title": title,
                "content": content,
                "category": category,
                "tags": tags or [],
                "views": 0,
                "likes": 0,
                "comments_count": 0,
            }).execute()
            return response.data[0]["id"] if response.data else None
        except Exception as e:
            logger.error(f"Supabase create_post error: {e}")
            return None

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    tags_json = json.dumps(tags) if tags else None
    cursor.execute("""
        INSERT INTO posts (user_id, user_name, title, content, category, tags)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (user_id, f"ë¸”ë¡œê±°{user_id % 10000:04d}", title, content, category, tags_json))
    post_id = cursor.lastrowid
    conn.commit()
    conn.close()
    return post_id


def get_posts(
    category: str = None,
    sort_by: str = "recent",
    limit: int = 20,
    offset: int = 0,
    search: str = None
) -> list:
    """ê²Œì‹œê¸€ ëª©ë¡ ì¡°íšŒ - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            query = supabase.table("posts").select("*").eq("is_deleted", False)

            if category:
                query = query.eq("category", category)

            if search:
                query = query.or_(f"title.ilike.%{search}%,content.ilike.%{search}%")

            # ì •ë ¬
            if sort_by == "popular":
                query = query.order("likes", desc=True).order("created_at", desc=True)
            elif sort_by == "comments":
                query = query.order("comments_count", desc=True).order("created_at", desc=True)
            else:
                query = query.order("is_pinned", desc=True).order("created_at", desc=True)

            response = query.range(offset, offset + limit - 1).execute()

            result = []
            for row in response.data:
                row['author'] = f"ë¸”ë¡œê±°{row['user_id'] % 10000:04d}"
                row['tags'] = row.get('tags') or []
                result.append(row)
            return result
        except Exception as e:
            logger.error(f"Supabase get_posts error: {e}")
            return []

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    query = "SELECT * FROM posts WHERE is_deleted = FALSE"
    params = []

    if category:
        query += " AND category = ?"
        params.append(category)

    if search:
        query += " AND (title LIKE ? OR content LIKE ?)"
        params.extend([f"%{search}%", f"%{search}%"])

    if sort_by == "popular":
        query += " ORDER BY likes DESC, created_at DESC"
    elif sort_by == "comments":
        query += " ORDER BY comments_count DESC, created_at DESC"
    else:
        query += " ORDER BY is_pinned DESC, created_at DESC"

    query += " LIMIT ? OFFSET ?"
    params.extend([limit, offset])

    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    result = []
    for row in rows:
        data = dict(row)
        data['tags'] = json.loads(data['tags']) if data.get('tags') else []
        data['author'] = f"ë¸”ë¡œê±°{data['user_id'] % 10000:04d}"
        result.append(data)
    return result


def get_post(post_id: int, user_id: int = None) -> dict:
    """ê²Œì‹œê¸€ ìƒì„¸ ì¡°íšŒ - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("posts").select("*").eq("id", post_id).eq("is_deleted", False).execute()
            if not response.data:
                return None

            data = response.data[0]

            # ì¡°íšŒìˆ˜ ì¦ê°€
            supabase.table("posts").update({"views": data.get("views", 0) + 1}).eq("id", post_id).execute()

            data['tags'] = data.get('tags') or []
            data['author'] = f"ë¸”ë¡œê±°{data['user_id'] % 10000:04d}"
            data['is_mine'] = user_id == data['user_id'] if user_id else False

            # ì¢‹ì•„ìš” ì—¬ë¶€
            if user_id:
                like_response = supabase.table("post_likes").select("id").eq("post_id", post_id).eq("user_id", user_id).execute()
                data['is_liked'] = len(like_response.data) > 0
            else:
                data['is_liked'] = False

            return data
        except Exception as e:
            logger.error(f"Supabase get_post error: {e}")
            return None

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM posts WHERE id = ? AND is_deleted = FALSE", (post_id,))
    row = cursor.fetchone()

    if not row:
        conn.close()
        return None

    cursor.execute("UPDATE posts SET views = views + 1 WHERE id = ?", (post_id,))
    conn.commit()

    data = dict(row)
    data['tags'] = json.loads(data['tags']) if data.get('tags') else []
    data['author'] = f"ë¸”ë¡œê±°{data['user_id'] % 10000:04d}"
    data['is_mine'] = user_id == data['user_id'] if user_id else False

    if user_id:
        cursor.execute("SELECT 1 FROM post_likes WHERE post_id = ? AND user_id = ?", (post_id, user_id))
        data['is_liked'] = cursor.fetchone() is not None
    else:
        data['is_liked'] = False

    conn.close()
    return data


def update_post(post_id: int, update_data: dict) -> bool:
    """ê²Œì‹œê¸€ ìˆ˜ì • - Supabase ë˜ëŠ” SQLite"""
    update_data['updated_at'] = datetime.now().isoformat()

    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("posts").update(update_data).eq("id", post_id).execute()
            return len(response.data) > 0
        except Exception as e:
            logger.error(f"Supabase update_post error: {e}")
            return False

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()

    if 'tags' in update_data and isinstance(update_data['tags'], list):
        update_data['tags'] = json.dumps(update_data['tags'])

    set_clause = ", ".join([f"{k} = ?" for k in update_data.keys()])
    values = list(update_data.values()) + [post_id]

    cursor.execute(f"UPDATE posts SET {set_clause} WHERE id = ?", values)
    conn.commit()
    conn.close()
    return True


def delete_post(post_id: int) -> bool:
    """ê²Œì‹œê¸€ ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ) - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("posts").update({"is_deleted": True}).eq("id", post_id).execute()
            return len(response.data) > 0
        except Exception as e:
            logger.error(f"Supabase delete_post error: {e}")
            return False

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("UPDATE posts SET is_deleted = TRUE WHERE id = ?", (post_id,))
    conn.commit()
    conn.close()
    return True


def like_post(post_id: int, user_id: int) -> dict:
    """ê²Œì‹œê¸€ ì¢‹ì•„ìš” í† ê¸€ - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            # ì´ë¯¸ ì¢‹ì•„ìš” í–ˆëŠ”ì§€ í™•ì¸
            existing = supabase.table("post_likes").select("id").eq("post_id", post_id).eq("user_id", user_id).execute()

            if existing.data:
                # ì¢‹ì•„ìš” ì·¨ì†Œ
                supabase.table("post_likes").delete().eq("post_id", post_id).eq("user_id", user_id).execute()
                # likes ê°ì†Œ
                post = supabase.table("posts").select("likes").eq("id", post_id).execute()
                if post.data:
                    new_likes = max(0, post.data[0].get("likes", 0) - 1)
                    supabase.table("posts").update({"likes": new_likes}).eq("id", post_id).execute()
                return {"success": True, "liked": False, "message": "ì¢‹ì•„ìš” ì·¨ì†Œ"}
            else:
                # ì¢‹ì•„ìš”
                supabase.table("post_likes").insert({"post_id": post_id, "user_id": user_id}).execute()
                # likes ì¦ê°€
                post = supabase.table("posts").select("likes").eq("id", post_id).execute()
                if post.data:
                    new_likes = post.data[0].get("likes", 0) + 1
                    supabase.table("posts").update({"likes": new_likes}).eq("id", post_id).execute()
                return {"success": True, "liked": True, "message": "ì¢‹ì•„ìš” ì™„ë£Œ"}
        except Exception as e:
            logger.error(f"Supabase like_post error: {e}")
            return {"success": False, "message": str(e)}

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT 1 FROM post_likes WHERE post_id = ? AND user_id = ?", (post_id, user_id))
    existing = cursor.fetchone()

    if existing:
        cursor.execute("DELETE FROM post_likes WHERE post_id = ? AND user_id = ?", (post_id, user_id))
        cursor.execute("UPDATE posts SET likes = likes - 1 WHERE id = ?", (post_id,))
        result = {"success": True, "liked": False, "message": "ì¢‹ì•„ìš” ì·¨ì†Œ"}
    else:
        cursor.execute("INSERT INTO post_likes (post_id, user_id) VALUES (?, ?)", (post_id, user_id))
        cursor.execute("UPDATE posts SET likes = likes + 1 WHERE id = ?", (post_id,))
        result = {"success": True, "liked": True, "message": "ì¢‹ì•„ìš” ì™„ë£Œ"}

    conn.commit()
    conn.close()
    return result


def create_post_comment(post_id: int, user_id: int, content: str, parent_id: int = None) -> int:
    """ê²Œì‹œê¸€ ëŒ“ê¸€ ì‘ì„± - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("post_comments").insert({
                "post_id": post_id,
                "user_id": user_id,
                "user_name": f"ë¸”ë¡œê±°{user_id % 10000:04d}",
                "content": content,
                "parent_id": parent_id,
            }).execute()

            if response.data:
                # ëŒ“ê¸€ ìˆ˜ ì¦ê°€
                post = supabase.table("posts").select("comments_count").eq("id", post_id).execute()
                if post.data:
                    new_count = post.data[0].get("comments_count", 0) + 1
                    supabase.table("posts").update({"comments_count": new_count}).eq("id", post_id).execute()
                return response.data[0]["id"]
            return None
        except Exception as e:
            logger.error(f"Supabase create_post_comment error: {e}")
            return None

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO post_comments (post_id, user_id, content, parent_id)
        VALUES (?, ?, ?, ?)
    """, (post_id, user_id, content, parent_id))
    comment_id = cursor.lastrowid
    cursor.execute("UPDATE posts SET comments_count = comments_count + 1 WHERE id = ?", (post_id,))
    conn.commit()
    conn.close()
    return comment_id


def get_post_comments(post_id: int) -> list:
    """ê²Œì‹œê¸€ ëŒ“ê¸€ ì¡°íšŒ - Supabase ë˜ëŠ” SQLite"""
    if USE_SUPABASE and supabase:
        try:
            response = supabase.table("post_comments").select("*").eq("post_id", post_id).eq("is_deleted", False).order("created_at").execute()
            result = []
            for row in response.data:
                row['author'] = f"ë¸”ë¡œê±°{row['user_id'] % 10000:04d}"
                result.append(row)
            return result
        except Exception as e:
            logger.error(f"Supabase get_post_comments error: {e}")
            return []

    # SQLite fallback
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT * FROM post_comments
        WHERE post_id = ? AND is_deleted = FALSE
        ORDER BY created_at ASC
    """, (post_id,))
    rows = cursor.fetchall()
    conn.close()

    result = []
    for row in rows:
        data = dict(row)
        data['author'] = f"ë¸”ë¡œê±°{data['user_id'] % 10000:04d}"
        result.append(data)
    return result


# ì´ˆê¸°í™”
init_community_tables()
init_post_tables()
